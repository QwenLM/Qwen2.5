# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2024, Qwen Team
# This file is distributed under the same license as the Qwen package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: Qwen \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-10-31 15:08+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/framework/function_call.md:6 ccd2ce23128642729ef9e0bf9b5ceeb4
msgid "Function Calling"
msgstr "函数调用"

#: ../../source/framework/function_call.md:8 9f010b3894ec42b7847ad2bedc77f55e
msgid "Preface"
msgstr "前言"

#: ../../source/framework/function_call.md:10 04b86d0983884bc699f7a6823ccba875
msgid "Function calling with large language models is a huge and evolving topic. It is particularly important for AI applications:"
msgstr "使用大型语言模型进行函数调用 (Function Calling) 是一个庞大且不断发展的主题。这对AI应用尤为重要："

#: ../../source/framework/function_call.md:12 fb80a5158f95401b81aa50d2934168a7
msgid "either for AI-native applications that strive to work around the shortcomings of current AI technology,"
msgstr "无论是为了绕过当前AI技术的局限性，而设计的原生AI应用，"

#: ../../source/framework/function_call.md:13 4befb000bb0940c48d3b0070d9cce303
msgid "or for existing applications that seeks the integration of AI technology to improve performance, user interaction and experience, or efficiency."
msgstr "还是为了提升性能、用户体验或效率，寻求整合AI技术的现有应用。"

#: ../../source/framework/function_call.md:15 af958aa0bf4047cf8bcfb65f826460f1
msgid "This guide will not delve into those discussions or which role an LLM should play in an application and the related best practice. Those views are reflected in the design of AI application frameworks: from LangChain to LlamaIndex to QwenAgent."
msgstr "本指南不会深入讨论LLM在应用中应扮演的角色及相关的最佳实践。这些观点反映在AI应用框架的设计上：从LangChain到LlamaIndex再到QwenAgent。"

#: ../../source/framework/function_call.md:18 b9b530bc9330479b8d24baf595590963
msgid "Instead, we will talk about how Qwen2.5 can be used to support function calling and how it can be used to achieve your goals, from the inference usage for developing application to the inner workings for hardcore customizations.  In this guide,"
msgstr "相反，我们将讨论如何使用Qwen2.5来支持函数调用，以及如何利用它实现你的目标，从开发应用时的推理用途，到硬核定制的内部运作。在这个指南中，"

#: ../../source/framework/function_call.md:20 f0050a47fbb840acbbc4e6541845d3dd
msgid "We will first demonstrate how to use function calling with Qwen2.5."
msgstr "我们首先将展示如何使用Qwen2.5进行函数调用。"

#: ../../source/framework/function_call.md:21 45f11ec9169147af8437402b46851e60
msgid "Then, we will introduce the technical details on functional calling with Qwen2.5, which are mainly about the templates."
msgstr "接着，我们将介绍使用Qwen2.5进行函数调用的技术细节，主要涉及模板的使用。"

#: ../../source/framework/function_call.md:23 55dedacadd5e44d69485d1c09f3ea40c
msgid "Before starting, there is one thing we have not yet introduced, that is ..."
msgstr "在开始之前，还有一件事我们尚未介绍，那就是…"

#: ../../source/framework/function_call.md:25 fdb0bdc4af964153b4211dae67cb7a03
msgid "What is function calling?"
msgstr "什么是函数调用？"

#: ../../source/framework/function_call.md:28 71078c519b534f7fbd0f184e0c3d210a
msgid "There is another term \"tool use\" that may be used to refer to the same concept. While some may argue that tools are a generalized form of functions, at present, their difference exists only technically as different I/O types of programming interfaces."
msgstr "这一概念也可能被称为“工具使用” (\"tool use\")。虽然有人认为“工具”是“函数”的泛化形式，但在当前，它们的区别仅在技术层面上，表现为编程接口的不同输入输出类型。"

#: ../../source/framework/function_call.md:32 c0aa562c8c1244e694826bdf978b055b
msgid "Large language models (LLMs) are powerful things. However, sometimes LLMs by themselves are simply not capable enough."
msgstr "大型语言模型（LLMs）确实强大。然而，有时候单靠大型语言模型的能力还是不够的。"

#: ../../source/framework/function_call.md:34 16a34ac3823f40839a0c8804641b424a
msgid "On the one hand, LLMs have inherent modeling limitations.  For one, they do not know things that are not in their training data, which include those happened after their training ended. In addition, they learn things in the way of likelihood, which suggests that they may not be precise enough for tasks with fixed rule sets, e.g., mathematical computation."
msgstr "一方面，大型语言模型存在建模局限性。首先，对于训练数据中没有的信息，包括训练结束后发生的事情，它们并不了解。此外，它们通过概率方式学习，这意味着对于有固定规则集的任务，如数学计算，可能不够精确。"

#: ../../source/framework/function_call.md:37 e05094bf6a4f42b59abb217fc3ea310b
msgid "On the other hand, it is not easy to use LLMs as a Plug-and-Play service programmatically with other things. LLMs mostly talk in words that are open to interpretation and thus ambiguous, while other software or applications or systems talk in code and through programming interfaces that are pre-defined and fixed and structured."
msgstr "另一方面，将大型语言模型作为即插即用服务与其它系统进行编程式协作，并非易事。大型语言模型的表达多含主观解释成分，因而产生歧义；而其他软件、应用或系统则通过预定义、固定和结构化的代码及编程接口进行沟通。"

#: ../../source/framework/function_call.md:40 57d70cc84fec4da5b031855327b9073f
msgid "To this end, function calling establishes a common protocol that specifies how LLMs should interact with the other things. The procedure is mainly as follows:"
msgstr "为此，函数调用确立了一个通用协议，规定了大型语言模型应与其他实体互动的流程。主要流程如下："

#: ../../source/framework/function_call.md:42 b6659534ef7d49cea3f714668dc24bac
msgid "The application provides a set of functions and the instructions of the functions to an LLM."
msgstr "应用程序向大型语言模型提供一组函数及其使用说明。"

#: ../../source/framework/function_call.md:43 577dfc3cd65943dc8aaa91797bafabad
msgid "The LLM choose to or not to, or is forced to use one or many of the functions, in response to user queries."
msgstr "大型语言模型根据用户查询，选择使用或不使用，或被迫使用一个或多个函数。"

#: ../../source/framework/function_call.md:44 91f309a959c846059001774a0843f125
msgid "If the LLM chooses to use the functions, it states how the functions should be used based on the function instructions."
msgstr "如果大型语言模型选择使用这些函数，它会根据函数说明如何使用。"

#: ../../source/framework/function_call.md:45 06722f57a4fa4ebfafc27c95362ea1aa
msgid "The chosen functions are used as such by the application and the results are obtained, which are then given to the LLM if further interaction is needed."
msgstr "应用程序按照选择使用这些函数，并获取结果。如果需要进一步互动，结果将提供给大型语言模型。"

#: ../../source/framework/function_call.md:47 c5112c8be4a349608c5c017ee1ee3222
msgid "They are many ways for LLMs to understand and follow this protocol. As always, the key is prompt engineering or an internalized template known by the model. Qwen2.5 were pre-trained with various types of templates that could support function calling, so that users can directly make use of this procedure."
msgstr "大型语言模型理解并遵循此协议有多种方式。关键在于提示工程 (Prompt Engineering) 或模型内化的模板。Qwen2预先训练了多种支持函数调用的模板，以便用户可以直接利用这一过程。"

#: ../../source/framework/function_call.md:52 e392d371f88247d1abc8fd1d16e50ada
msgid "Inference with Function Calling"
msgstr "使用函数调用进行推理"

#: ../../source/framework/function_call.md:55 97b4792fe15d4ea592cbedf0823bb5d0
msgid "Please be aware that the inference usage is subject to change as the frameworks and the Qwen models evolve."
msgstr "请注意，随着框架和Qwen模型的不断演进，推理的使用方式可能会发生变化。"

#: ../../source/framework/function_call.md:58 82b1eec807eb40d3b9015b5dcd5d6d78
msgid "As function calling is essentially implemented using prompt engineering, you could manually construct the model inputs for Qwen2 models. However, frameworks with function calling support can help you with all that laborious work."
msgstr "由于函数调用本质上是通过提示工程实现的，您可以手动构建Qwen2模型的输入。但是，支持函数调用的框架可以帮助您完成所有繁重的工作。"

#: ../../source/framework/function_call.md:61 bb79cf3f3a24452f9d9ac4e095c94604
msgid "In the following, we will introduce the usage (via dedicated function calling chat template) with"
msgstr "接下来，我们将介绍（通过专用的函数调用模板）使用"

#: ../../source/framework/function_call.md:62 dd4d964420b44e4d8b0f05b5ad1fed96
msgid "**Qwen-Agent**,"
msgstr "**Qwen-Agent**，"

#: ../../source/framework/function_call.md:63 b9c2265d56364e1fa7d5644a4cc83231
msgid "**Hugging Face transformers**,"
msgstr "**Hugging Face transformers**，"

#: ../../source/framework/function_call.md:64 f7a99f4c8e8b4a099b84e5d79fe9bf53
msgid "**Ollama**, and"
msgstr "**Ollama**，和"

#: ../../source/framework/function_call.md:65 f35a2ddaa85f4042aa28240939a815ec
msgid "**vLLM**."
msgstr "**vLLM**。"

#: ../../source/framework/function_call.md:67 b2961d7ee635498c9072ed7ce07cab26
msgid "If you are familiar with the usage of OpenAI API, you could also directly use the OpenAI-compatible API services for Qwen2.5. However, not all of them support function calling for Qwen2.5. Currently, supported solutions include the self-hosted service by [Ollama](https://github.com/ollama/ollama/blob/main/docs/openai.md) or [vLLM](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html#tool-calling-in-the-chat-completion-api) and the cloud service of [ModelStudio \\[zh\\]](https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope#97e2b45391x08)."
msgstr "如果您熟悉OpenAI API的使用，您也可以直接使用适用于Qwen2.5的OpenAI兼容API服务。然而，并非所有服务都支持Qwen2.5的函数调用。目前，支持的解决方案包括由[Ollama](https//github.com/ollama/ollama/blob/main/docs/openai.md)或[vLLM](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html#tool-calling-in-the-chat-completion-api)提供的自托管服务和[阿里云百炼](https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope#97e2b45391x08)的云服务。"

#: ../../source/framework/function_call.md:71 2e4a327267bf46b186237695e2eed776
msgid "If you are familiar with application frameworks, e.g., LangChain, you can also use function calling abilities in Qwen2.5 via ReAct Prompting."
msgstr "如果您熟悉应用框架，例如LangChain，您也可以通过ReAct Prompting在Qwen2.5中使用函数调用功能。"

#: ../../source/framework/function_call.md:73 2af89ffaa80c467598a842928685099d
msgid "The Example Case"
msgstr "案例"

#: ../../source/framework/function_call.md:75 7c89bc3623af4930836b8c12425c5350
msgid "Let's also use an example to demonstrate the inference usage. We assume **Python 3.11** is used as the programming language."
msgstr "我们同样通过一个示例来展示推理的使用方法。假设我们使用的编程语言是**Python 3.11**。"

#: ../../source/framework/function_call.md:78 eec40bcd75c844ee9f55a37e06e62e2a
msgid "**Scenario**: Suppose we would like to ask the model about the temperature of a location. Normally, the model would reply that it cannot provide real-time information. But we have two tools that can be used to obtain the current temperature of and the temperature at a given date of a city respectively, and we would like the model to make use of them."
msgstr "**场景**：假设我们要询问模型某个地点的温度。通常，模型会回答无法提供实时信息。但我们有两个工具，可以分别获取城市的当前温度和指定日期的温度，我们希望模型能够利用这些工具。"

#: ../../source/framework/function_call.md:82 93d8898d252e4a8ba7b6ea298ab7379e
msgid "To set up the example case, you can use the following code:"
msgstr "为了这个示例案例，您可以使用以下代码："

#: ../../source/framework/function_call.md 8fc7a16fdd2b4a5bb8c5ccb03025e5fe
msgid "Preparation Code"
msgstr "准备代码"

#: ../../source/framework/function_call.md:189 32808545250d43d7840df97fe5e05de2
msgid "In particular, the tools should be described using JSON Schema and the messages should contain as much available information as possible. You can find the explanations of the tools and messages below:"
msgstr "工具应使用JSON Schema进行描述，消息应包含尽可能多的有效信息。您可以在下面找到工具和消息的解释："

#: ../../source/framework/function_call.md 8917791173f34c91adbe9aefe034af55
msgid "Example Tools"
msgstr "示例工具"

#: ../../source/framework/function_call.md:194 e70dfbfa00814b05bb6277f312c4e773
msgid "The tools should be described using the following JSON:"
msgstr "工具应使用以下JSON进行描述："

#: ../../source/framework/function_call.md:258 dfd9421f66bb4a599c1e6cd7cc280ee3
msgid "For each **tool**, it is a JSON object with two fields:"
msgstr "对于每个**工具**，它是一个具有两个字段的JSON object："

#: ../../source/framework/function_call.md:259 7ac637eef6bf4284a38b56d4a2d74189
msgid "`type`: a string specifying the type of the tool, currently only `\"function\"` is valid"
msgstr "`type`：string，用于指定工具类型，目前仅`\"function\"`有效"

#: ../../source/framework/function_call.md:260 e43763d903d14f2db88fb57eaf0fe2e3
msgid "`function`: an object detailing the instructions to use the function"
msgstr "`function`：object，详细说明了如何使用该函数"

#: ../../source/framework/function_call.md:262 38cd0bacbc5c489faa03b034bdf82317
msgid "For each **function**, it is a JSON object with three fields:"
msgstr "对于每个**function**，它是一个具有三个字段的JSON object："

#: ../../source/framework/function_call.md:263 be9e02b72eec41039e90a3ae3e142073
msgid "`name`: a string indicating the name of the function"
msgstr "`name`：string 表示函数名称"

#: ../../source/framework/function_call.md:264 5335f4fb22fd452da6bc9db888e585d0
msgid "`description`: a string describing what the function is used for"
msgstr "`description`：string 描述函数用途"

#: ../../source/framework/function_call.md:265 626f0415f54a4e769e3af15afb23c70b
msgid "`parameters`: [a JSON Schema](https://json-schema.org/learn/getting-started-step-by-step) that specifies the parameters the function accepts. Please refer to the linked documentation for how to compose a JSON Schema. Notable fields include `type`, `required`, and `enum`."
msgstr "`parameters`：[JSON Schema](https://json-schema.org/learn/getting-started-step-by-step)，用于指定函数接受的参数。请参阅链接文档以了解如何构建JSON Schema。值得注意的字段包括`type`、`required`和`enum`。"

#: ../../source/framework/function_call.md:267 e875d5e507104f2f9cec53fe37e0ad95
msgid "Most frameworks use the tool format and some may use the function format. Which one to use should be obvious according to the naming."
msgstr "大多数框架使用“工具”格式，有些可能使用“函数”格式。根据命名，应该很明显应该使用哪一个。"

#: ../../source/framework/function_call.md bdfd37b335ba474ab08873673a039bee
msgid "Example Messages"
msgstr "示例消息"

#: ../../source/framework/function_call.md:274 4727c5610d6a42beb39a1f4b0d1e2aed
msgid "Our query is `What's the temperature in San Francisco now? How about tomorrow?`. Since the model does not know what the current date is, let alone tomorrow, we should provide the date in the inputs. Here, we decide to supply that information in the system message after the default system message `You are Qwen, created by Alibaba Cloud. You are a helpful assistant.`. You could append the date to user message in your application code."
msgstr "我们的查询是`What's the temperature in San Francisco now? How about tomorrow?`。由于模型不知道当前日期，更不用说明天了，我们应该在输入中提供日期。在这里，我们决定在默认系统消息`You are Qwen, created by Alibaba Cloud. You are a helpful assistant.`之后的系统消息中提供该信息。您可以在应用程序代码中将日期附加到用户消息。"

#: ../../source/framework/function_call.md:287
#: ../../source/framework/function_call.md:550 0ad6d8b4d6ec44fd85244a486fa8a1bd
#: 0bea41c73ddb47d2bca74cd5686024b4
msgid "Qwen-Agent"
msgstr ""

#: ../../source/framework/function_call.md:289 4e25cdd9d29d4facbed0c6fb9c57b189
msgid "[Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) is actually a Python Agent framework for developing AI applications. Although its intended use cases are higher-level than efficient inference, it does contain the **canonical implementation** of function calling for Qwen2.5. It provides the function calling ability for Qwen2.5 to an OpenAI-compatible API through templates that is transparent to users."
msgstr "[Qwen-Agent](https://github.com/QwenLM/Qwen-Agent) 实际上是一个用于开发AI应用的Python智能体框架。尽管其设计用例比高效推理更高级，但它确实包含了Qwen2.5函数调用的**规范实现**。基于OpenAI兼容API，它可以通过模板为Qwen2.5提供了对用户透明的的函数调用能力。"

#: ../../source/framework/function_call.md:294 36e3ebb8faae4a81a2439c26ff7dd6fc
msgid "It's worth noting that since a lot of stuff can be done under the scene with application frameworks, currently the official function calling implementation for Qwen2.5 is very flexible and beyond simple templating, making it hard to adapt it other frameworks that use less capable templating engines."
msgstr "值得注意的是，由于应用框架可以在幕后完成大量工作，目前Qwen2.5官方的函数调用实现非常灵活且超出了简单的模板化，这使得它难以适应那些使用能力较弱的模板引擎的其他框架。"

#: ../../source/framework/function_call.md:296 8041585123404239a1cd84e4a80e4b4a
msgid "Before starting, let's make sure the latest library is installed:"
msgstr "在开始之前，让我们确保已安装了最新的库："

#: ../../source/framework/function_call.md:301 c97a7cb1d3ec4d05b36cb8f26434e211
#, fuzzy
msgid "For this guide, we are at version v0.0.10."
msgstr "对于本指南，我们处于版本v0.0.9。"

#: ../../source/framework/function_call.md:303
#: ../../source/framework/function_call.md:449
#: ../../source/framework/function_call.md:665
#: ../../source/framework/function_call.md:777 0ca5827eab5244349f3bcd737837d3b1
#: 2ddd5e1b5e7b48b4ba0faaaacde35f9d 561bafb9c0544dd4a5acdabb8c4a1c8e
#: 61a4e54b110444d3a673216888760646
msgid "Preparing"
msgstr "准备工作"

#: ../../source/framework/function_call.md:305 e5ad31541ed94166954336e769d3eae2
msgid "Qwen-Agent can wrap an OpenAI-compatible API that does not support function calling. You can serve such an API with most inference frameworks or obtain one from cloud providers like DashScope or Together."
msgstr "Qwen-Agent可以封装一个不支持函数调用的OpenAI兼容API。您可以使用大多数推理框架来提供此类API，或者从DashScope或Together等云提供商处获取一个。"

#: ../../source/framework/function_call.md:308 5f91cc1b0fd74c6fa6def3ee17135abf
msgid "Assuming there is an OpenAI-compatible API at `http://localhost:8000/v1`, Qwen-Agent provides a shortcut function `get_chat_model` to obtain a model inference class with function calling support:"
msgstr "假设在`http://localhost:8000/v1`处有一个OpenAI兼容API，Qwen-Agent提供了一个快捷函数`get_chat_model`，用于获取具有函数调用支持的模型推理类："

#: ../../source/framework/function_call.md:320 9ef52a1acfc3406fb780282da32355d9
msgid "In the above, `model_server` is the `api_base` common used in other OpenAI-compatible API clients. It is advised to provide the `api_key` (but not via plaintext in the code), even if the API server does not check it, in which case, you can set it to anything."
msgstr "在上述代码中，`model_server`是其他OpenAI兼容API客户端常用的`api_base`。建议您提供`api_key`（但不要以明文形式出现在代码中），即使API服务器不检查它，在这种情况下，您可以将其设置为任何值。"

#: ../../source/framework/function_call.md:323 6429288385f345178ee75dc255b367cf
msgid "For model inputs, the common message structure for system, user, and assistant history should be used:"
msgstr "对于模型输入，应使用系统、用户和助手历史记录的通用消息结构："

#: ../../source/framework/function_call.md:333 9305b473cda14f3fb6d9df13d5e64f7a
msgid "We add the current date to the system message so that the \"tomorrow\" in the user message is anchored. It can also be added to the user message if one desires."
msgstr "我们在系统消息中添加当前日期，以便使用户消息中的\"明天\"有明确的参照点。如果需要，也可以将其添加到用户消息中。"

#: ../../source/framework/function_call.md:336 0d93723b9357413985cc48fa6f596dea
msgid "At the time, Qwen-Agent works with functions instead of tools. This requires a small change to our tool descriptions, that is, extracting the function fields:"
msgstr "目前，Qwen-Agent使用“函数”而非“工具”。这需要对我们工具描述进行一些小的更改，即提取函数字段："

#: ../../source/framework/function_call.md:343
#: ../../source/framework/function_call.md:490
#: ../../source/framework/function_call.md:679
#: ../../source/framework/function_call.md:808 9381d3eec9a54141bd6253e1f5c7d6a4
#: b4f9731b4c7b4215a92caac7b9e206ac b5d083e469c748d4b4fb2ba62f14ff97
#: e5e375d942824ea19785aa36892768ed
msgid "Tool Calls and Tool Results"
msgstr "工具调用和工具结果"

#: ../../source/framework/function_call.md:345 46ec50a609cc4694ba32821944ea19bd
msgid "To interact with the model, the `chat` method should be used:"
msgstr "为了与模型交互，应使用`chat`方法："

#: ../../source/framework/function_call.md:357 b558319e1d6d4f489a1fc753adf4bb68
msgid "In the above code, the `chat` method receives the `messages`, the `functions`, and an `extra_generate_cfg` parameter. You can put sampling parameters, such as `temperature`, and `top_p`, in the `extra_generate_cfg`. Here, we add to it a special control `parallel_function_calls` provided by Qwen-Agent. As its name suggests, it will enable parallel function calls, which means that the model may generate multiple function calls for a single turn as it deems fit."
msgstr "在上述代码中，`chat`方法接收`messages`、`functions`以及一个`extra_generate_cfg`参数。你可以在`extra_generate_cfg`中放入诸如`temperature`和`top_p`等采样参数。这里，我们添加了Qwen-Agent提供的特殊控制`parallel_function_calls`。顾名思义，它将启用并行函数调用，这意味着模型可能为单次请求生成多个函数调用，按照其判断进行。"

#: ../../source/framework/function_call.md:362 42f4045d28b04eafa62d8340f77a73a0
msgid "The `chat` method returns a generator of list, each of which may contain multiple messages. Since we enable `parallel_function_calls`, we should get two messages in the responses:"
msgstr "`chat`方法返回一个列表的生成器，每个列表可能包含多条消息。因为我们启用了`parallel_function_calls`，我们应该在响应中得到两条消息："

#: ../../source/framework/function_call.md:372 d11c86fdd84847559d004eeea7675d2c
msgid "As we can see, Qwen-Agent attempts to parse the model generation in an easier to use structural format. The details related to function calls are placed in the `function_call` field of the messages:"
msgstr "我们可以看到，Qwen-Agent试图以更易于使用的结构化格式解析模型生成。与函数调用相关的详细信息被放置在消息的`function_call`字段中："

#: ../../source/framework/function_call.md:374 58dc6f7f89674df4a0cbeabd1c0321d4
msgid "`name`: a string representing the function to call"
msgstr "`name`：代表要调用的函数的字符串"

#: ../../source/framework/function_call.md:375 3e926164c377453b9d660712e76f6cd3
msgid "`arguments`: a JSON-formatted string representing the arguments the function should be called with"
msgstr "`arguments`：表示函数应带有的参数的JSON格式字符串"

#: ../../source/framework/function_call.md:377 4d5d234b590445d0999c4d0927752180
msgid "Note that Qwen2.5-7B-Instruct is quite capable:"
msgstr "请注意，Qwen2.5-7B-Instruct相当强大："

#: ../../source/framework/function_call.md:378 3d1127f609834623b234568a33ca2ac8
msgid "It has followed the function instructions to add the state and the country to the location."
msgstr "它遵循函数指令，在位置中添加了州和国家。"

#: ../../source/framework/function_call.md:379 4252298eef8c4f88b7a415f46fa91c0b
msgid "It has correctly induced the date of tomorrow and given in the format required by the function."
msgstr "它正确地推断出明天的日期，并以函数要求的格式给出。"

#: ../../source/framework/function_call.md:381 bf6ae18a02824f92b83ea5400bfce383
msgid "Then comes the critical part -- checking and applying the function call:"
msgstr "接下来是关键部分——检查和应用函数调用："

#: ../../source/framework/function_call.md:397 e612beb286524d5282213311772953d1
msgid "To get tool results:"
msgstr "获取工具结果："

#: ../../source/framework/function_call.md:398 13aca689fb8d477eb9e197b62b91a445
msgid "line 1: We should iterate the function calls in the order the model generates them."
msgstr "第1行：我们应该按模型生成它们的顺序迭代函数调用。"

#: ../../source/framework/function_call.md:399 bc05b673980c45649953276f886f9a69
msgid "line 2: We can check if a function call is needed as deemed by the model by checking the `function_call` field of the generated messages."
msgstr "第2行：通过检查生成消息的`function_call`字段，我们可以查看是否需要按模型判断进行函数调用。"

#: ../../source/framework/function_call.md:400 51b5475290ee450fa7e24fd1effc0c81
msgid "line 3-4: The related details including the name and the arguments of the function can also be found there, which are `name` and `arguments` respectively."
msgstr "第3-4行：相关详情，包括函数名称和参数，也可以在那里找到，分别是`name`和`arguments`。"

#: ../../source/framework/function_call.md:401 65abc5c8a345492e8094a3b07a9eb727
msgid "line 6: With the details, one should call the function and obtain the results. Here, we assume there is a function named [`get_function_by_name`](#prepcode) to help us get the related function by its name."
msgstr "第6行：有了这些细节，应该调用函数并获取结果。这里，我们假设有一个名为[`get_function_by_name`](#prepcode)的函数来帮助我们根据名称获取相关函数。"

#: ../../source/framework/function_call.md:403 bc84dd1d20fa4089a50631598213f2c7
msgid "line 8-12: With the result obtained, add the function result to the messages as `content` and with `role` as `\"function\"`."
msgstr "第8-12行：获得结果后，将函数结果作为`content`添加到消息中，并将`role`设置为`\"function\"`。"

#: ../../source/framework/function_call.md:405 28f0bee74fa6407c8b5e474ba2bdd665
msgid "Now the messages are"
msgstr "现在消息是"

#: ../../source/framework/function_call.md:417
#: ../../source/framework/function_call.md:619
#: ../../source/framework/function_call.md:745
#: ../../source/framework/function_call.md:895 2736357a13d94da384340db2ae95afae
#: 4dd997b6ace9421eb4803dc09336f014 8b3d566ce9a047a9b90d57e0874a4861
#: e00c38376a2240a3867a4579bc6adad3
msgid "Final Response"
msgstr "最终响应"

#: ../../source/framework/function_call.md:419 54ae3d9ddd334669b6cacc223705371a
msgid "Finally, run the model again to get the final model results:"
msgstr "最后，再次运行模型以获取最终的模型结果："

#: ../../source/framework/function_call.md:427 480d13c4927542508eb0a0263e3b97e5
msgid "The final response should be like"
msgstr "最终响应应如下所示"

#: ../../source/framework/function_call.md:433
#: ../../source/framework/function_call.md:550 7695dfa2febb4cf6839ca2123d5f9f67
#: c71ee305fc48414ab8a155ebd3ac0386
msgid "Hugging Face transformers"
msgstr ""

#: ../../source/framework/function_call.md:435 ee318e4da14742749cc1365256f37955
msgid "Since function calling is based on prompt engineering and templates, `transformers` supports it with its tokenizer utilities, in particular, the `tokenizer.apply_chat_template` method, which hides the sophistication of constructing the model inputs, using the Jinja templating engine. However, it means that users should handle the model output part on their own, which includes parsing the generated function call message."
msgstr "由于函数调用基于提示工程和模板，`transformers`通过其tokenizer工具支持这一功能，特别是`tokenizer.apply_chat_template`方法，它利用Jinja模板引擎隐藏了构建模型输入的复杂性。然而，这意味着用户需要自行处理模型输出部分，包括解析生成的函数调用消息。"

#: ../../source/framework/function_call.md:438 6cfaa3e1175e4adf8bc57b308c86616d
msgid "The blog piece [_Tool Use, Unified_](https://huggingface.co/blog/unified-tool-use) is very helpful in understanding its design. Be sure to take a look."
msgstr "博客文章[_Tool Use, Unified_](https://huggingface.co/blog/unified-tool-use)对于理解其设计非常有帮助。务必阅读一下。"

#: ../../source/framework/function_call.md:441 90346239c1544ad4a3653005428eac34
msgid "Tool use API is available in transformers since v4.42.0. Before starting, let's check that:"
msgstr "自v4.42.0版本起，transformers中提供了工具使用API。在开始之前，让我们确认这一点："

#: ../../source/framework/function_call.md:447 87ab88c19bd740ee8ca2400de33866e9
msgid "For this guide, we are at version v4.44.2."
msgstr "对于本指南，我们处于v4.44.2版本。"

#: ../../source/framework/function_call.md:451 8e92887ef8c948ff81890cb3434178c3
msgid "For Qwen2.5, the chat template in `tokenizer_config.json` has already included support for the Hermes-style tool use.  We simply need to load the model and the tokenizer:"
msgstr "对于 Qwen2.5，`tokenizer_config.json` 中的聊天模板已经包含了对 Hermes 风格工具调用的支持。我们只需加载模型和分词器："

#: ../../source/framework/function_call.md:467
#: ../../source/framework/function_call.md:669
#: ../../source/framework/function_call.md:785 635c0d8faaeb4be58b5037ff71bf2a65
#: b6ad03363e8f4cf48b55c9921f2b3d66 f939c3127b964bec95033bc7dea2bc07
msgid "The inputs are the same with those in [the preparation code](#prepcode):"
msgstr "输入与[准备代码](#prepcode)中的相同："

#: ../../source/framework/function_call.md:474 7daf3af611c246129ad9c9042dcffeec
msgid "In `transformers`, you can also directly use Python functions as tools with certain constraints[^get_json_schema_note]:"
msgstr "在`transformers`中，您也可以直接将Python函数作为工具使用，但需遵循特定约束[^get_json_schema_note]："

#: ../../source/framework/function_call.md:492 d1e97046fb7e42789b026db4036c829a
msgid "To construct the input sequence, we should use the `apply_chat_template` method and then let the model continue the texts:"
msgstr "为了构造输入序列，我们应该使用`apply_chat_template`方法，然后让模型继续生成文本："

#: ../../source/framework/function_call.md:501 30b40ca2a86f4d91a2511679f1b54ec9
msgid "The output texts should be like"
msgstr "输出文本应如下所示："

#: ../../source/framework/function_call.md:511 fb174fd2eb9d4b019df09ae657653acc
msgid "Now we need to do two things:"
msgstr "现在我们需要做两件事："

#: ../../source/framework/function_call.md:512 40792e13e67d456c8b6baf2ce300affb
msgid "Parse the generated tool calls to a message and add them to the messages, so that the model knows which tools are used."
msgstr "解析生成的工具调用为一条消息，并将其添加到消息列表中，以便模型了解所使用的工具。"

#: ../../source/framework/function_call.md:513 f1ffca91768d4f37819912264e5b9860
msgid "Obtain the results of the tools and add them to the messages, so that the model knows the results of the tool calls."
msgstr "获取工具的结果并将其添加到消息列表中，以便模型了解工具调用的结果。"

#: ../../source/framework/function_call.md:515 66814c399da441fd93275a6dd694a1a2
msgid "In `transformers`, the tool calls should be a field of assistant messages. Let's use a simple function called `try_parse_tool_calls` to parse the tool calls:"
msgstr ""

#: ../../source/framework/function_call.md:547 f4f68f264dfb45d79d46a1eb92ac0938
msgid "This function does not cover all possible scenarios and thus is prone to errors. But it should suffice for the purpose of this guide."
msgstr ""

#: ../../source/framework/function_call.md:551 36b045c72aa34fbfb99f821957ef518b
msgid "The template in the `tokenizer_config.json` assumes that the generated content alongside tool calls is in the same message instead of separate assistant messages, e.g.,"
msgstr "`tokenizer_config.json` 中的模板假设生成的内容和工具调用是在同一消息中，而不是分开的助手消息，例如："

#: ../../source/framework/function_call.md:561 3cf1cfef9dd746ae98e4952834e49e93
msgid "instead of"
msgstr "而非"

#: ../../source/framework/function_call.md:578 a784c2f4f2f2429a94ccea14c86288f0
msgid "This is implemented roughly in `try_parse_tool_calls` but keep that in mind if you are writing your own tool call parser."
msgstr "`try_parse_tool_calls` 中大致实现了这一约定，但如果你正在编写自己的工具调用解析器，请留意这一点。"

#: ../../source/framework/function_call.md:599 87da78268fd64831a3e219dc250151e8
msgid "The messages now should be like"
msgstr "现在消息应如下所示："

#: ../../source/framework/function_call.md:613 f44ee60c934c46b6991bba9bfef0d364
msgid "The messages are similar to those of Qwen-Agent, but there are some major differences:"
msgstr "这些消息类似于Qwen-Agent的消息，但存在一些主要差异："

#: ../../source/framework/function_call.md:614 1b9f714d423d420d8315a64c8bc34f2b
msgid "Tools instead of functions"
msgstr "工具而非函数"

#: ../../source/framework/function_call.md:615 f45905329dc6487ab9e584428f52824a
msgid "Parallel calls are by default"
msgstr "默认情况下为并行调用"

#: ../../source/framework/function_call.md:616 99c78f051cdd4b4ab707fce4783b3a10
msgid "Multiple tool calls as a list in a single assistant message, instead of multiple messages."
msgstr "多个工具调用以列表形式在一个助手消息中，而不是多个消息"

#: ../../source/framework/function_call.md:617 452f5e395f304d5e939f7019186456ae
msgid "The function arguments are parsed into a dict if it is a valid JSON-formatted string."
msgstr "如果函数参数是有效的JSON格式字符串，则将其解析为字典。"

#: ../../source/framework/function_call.md:621 0bfc5132d15442f0aa28176e389d9a0a
msgid "Then it's time for the model to generate the actual response for us based on the tool results.  Let's query the model again:"
msgstr "现在是时候根据工具结果，让模型为我们生成实际响应了。再次查询模型："

#: ../../source/framework/function_call.md:631 e31ba1573dee4927b9bd67e7f8ffb164
msgid "The output_text should be like"
msgstr "输出文本应如下所示："

#: ../../source/framework/function_call.md:636 ba91087f1a0849f2ad90965580671a51
msgid "Add the result text as an assistant message and the final messages should be ready for further interaction:"
msgstr "将结果文本作为助手消息添加，最终消息应准备好进行进一步交互："

#: ../../source/framework/function_call.md:550
#: ../../source/framework/function_call.md:641 66c7357bac044765910c4d6cd89ac4cc
#: 689ed5c1e1f64c37a6fc707c98381cfe
msgid "Ollama"
msgstr ""

#: ../../source/framework/function_call.md:643 70701fb141ee41e29f02cc23a4a95146
msgid "Ollama is a set of tools for serving LLMs locally.  It also relies on its template implementation to support function calling. Different from transformers, which is written in Python and uses the Jinja template whose syntax is heavily inspired by Django and Python, Ollama, which is mostly written in Go, uses Go's [text/template](https://pkg.go.dev/text/template) packages. In addition, Ollama implements internally a helper function so that it can automatically parse the generated tool calls in texts to structured messages if the format supported."
msgstr "Ollama是一套用于本地部署LLMs的工具集。它还依赖于其模板实现来支持函数调用。不同于使用Python编写的transformers，采用了受Django和Python语法启发的Jinja模板，主要用Go编写的Ollama则使用了Go的[text/template](https://pkg.go.dev/text/template)包。此外，Ollama内部实现了辅助函数，如果格式被支持的话，它可以自动解析文本中生成的工具调用为结构化的消息。"

#: ../../source/framework/function_call.md:648 c4f62ef5b25943cdb9b4f582e83844e1
msgid "You could check the [Tool support](https://ollama.com/blog/tool-support) blog post first."
msgstr "您可以先查阅[Tool support](https://ollama.com/blog/tool-support)的博客文章。"

#: ../../source/framework/function_call.md:650 97a207d3fd2b46f79f625f2a5aa4c648
msgid "Tool support has been available in Ollama since v0.3.0. You can run the following to check the Ollama version:"
msgstr "自v0.3.0版本以来，Ollama已经提供了工具支持。您可以运行以下命令来检查Ollama的版本："

#: ../../source/framework/function_call.md:655 9e56d6722ad64f98826d9762864fdf3e
msgid "If lower than expected, follow [the official instructions](https://ollama.com/download) to install the latest version."
msgstr "如果版本低于预期，请遵循[官方说明](https://ollama.com/download)安装最新版本。"

#: ../../source/framework/function_call.md:657 79742bd643974c18adfbced78db33f8e
msgid "In this guide, we will aslo use [ollama-python](https://github.com/ollama/ollama-python), before starting, make sure it is available in your environment:"
msgstr "在本指南中，我们将使用[ollama-python](https://github.com/ollama/ollama-python)，在开始之前，请确保您的环境中已安装此库："

#: ../../source/framework/function_call.md:662 42ae5a4878ef4dc5af999c6759b01ffd
msgid "For this guide, the `ollama` binary is at v0.3.9 and the `ollama` Python library is at v0.3.2."
msgstr "对于本指南，`ollama`二进制文件的版本为v0.3.9，`ollama` Python库的版本为v0.3.2。"

#: ../../source/framework/function_call.md:667 113b38b72e0c427fbdcbc7fe20119d38
msgid "The messages structure used in Ollama is the same with that in `transformers` and the template in [Qwen2.5 Ollama models](https://ollama.com/library/qwen2.5) has supported tool use."
msgstr "Ollama 中使用的消息结构与 `transformers` 中的相同，并且 [Qwen2.5 Ollama 模型](https://ollama.com/library/qwen2.5) 的模板已经支持工具调用。"

#: ../../source/framework/function_call.md:676 587a9bb06e0343cbaed7845c22abdb73
msgid "Note that you cannot pass Python functions as tools directly and `tools` has to be a `dict`."
msgstr "请注意，您不能直接将Python函数作为工具传递，`tool`的类型必须是`dict`。"

#: ../../source/framework/function_call.md:681 04cba30ce1de44cea76dcec478af06e6
msgid "We can use the `ollama.chat` method to directly query the underlying API:"
msgstr "我们可以使用`ollama.chat`方法直接查询底层API："

#: ../../source/framework/function_call.md:693 17c2d6a6b51742bda2218efca6f400b2
msgid "The main fields in the response could be:"
msgstr "响应中的主要字段可能是："

#: ../../source/framework/function_call.md:708 85f0ce2027a44a30bfde39a2b73e416e
#, fuzzy
msgid "Ollama's tool call parser has succeeded in parsing the tool results. If not, you may refine [the `try_parse_tool_calls` function above](#parse-function). Then, we can obtain the tool results and add them to the messages. The following is basically the same with `transformers`:"
msgstr "Ollama的工具调用解析器成功解析出了工具调用。[^tool_call_arg_format] 但如果失败了，您可能需要尝试改进[上面的`try_parse_tool_calls`函数](#prepcode)。 然后，我们可以获取工具的结果并将其添加到消息中。以下操作基本上与`transformers`相同："

#: ../../source/framework/function_call.md:731
#: ../../source/framework/function_call.md:881 42d281414b464f769802967b95bb468e
#: be3b9be798f34b6fadc29460bc2c6f11
msgid "The messages are now like"
msgstr "现在消息如下："

#: ../../source/framework/function_call.md:747 30104b1bf917492ab1bdde5f5653f52f
msgid "The rest are easy:"
msgstr "剩下的部分很简单："

#: ../../source/framework/function_call.md:758 ed9a68b8a5294c52a4b3b451d733887e
msgid "The final message should be like the following:"
msgstr "最终的消息应该如下所示："

#: ../../source/framework/function_call.md:550
#: ../../source/framework/function_call.md:764 53bd024952fc4fe29adebda14f118b6b
#: e50be39ef18e46efbb6790335579d519
msgid "vLLM"
msgstr ""

#: ../../source/framework/function_call.md:766 e782ca170aa2400ba65d70564f6889cb
msgid "vLLM is a fast and easy-to-use library for LLM inference and serving. It uses the tokenizer from `transformers` to format the input, so we should have no trouble preparing the input. In addition, vLLm also implements helper functions so that generated tool calls can be parsed automatically if the format is supported."
msgstr "vLLM 是一个快速且易于使用的库，用于大型语言模型的推理和部署。它使用 `transformers` 中的分词器来格式化输入，因此我们在准备输入时应该不会遇到任何问题。此外，vLLM 还实现了辅助函数，以便在支持的情况下自动解析生成的工具调用。"

#: ../../source/framework/function_call.md:770 5e9ff0f339a840d3a874906ad4758cb2
msgid "Tool support has been available in `vllm` since v0.6.0.  Be sure to install a version that supports tool use. For more information, check the [vLLM documentation](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html#tool-calling-in-the-chat-completion-api)."
msgstr "工具支持自 v0.6.0 版本起已在 `vllm` 中可用。请确保安装了一个支持工具调用的版本。更多信息，请查阅 [vLLM 文档](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html#tool-calling-in-the-chat-completion-api)"

#: ../../source/framework/function_call.md:774 2e3d641e5004473d9aa46f3d104043ec
msgid "For this guide, we are at version v0.6.1.post2. We will use the OpenAI-Compatible API by `vllm` with the API client from the `openai` Python library."
msgstr "在本指南中，我们使用的是 v0.6.1.post2 版本。我们将使用 `vllm` 提供的 OpenAI 兼容 API，并通过 `openai` Python 库的 API 客户端来进行操作。"

#: ../../source/framework/function_call.md:779 9cc91984ea30451d9eade5e84c28a071
msgid "For Qwen2.5, the chat template in tokenizer_config.json has already included support for the Hermes-style tool use. We simply need to start a OpenAI-compatible API with vLLM:"
msgstr "对于 Qwen2.5，`tokenizer_config.json` 中的聊天模板已经包含了对 Hermes 风格工具调用的支持。我们只需要启动一个由 vLLM 提供的 OpenAI 兼容 API 即可："

#: ../../source/framework/function_call.md:792 23914bfeb1a1483fbe2b088106e42d4e
msgid "Let's also initialize the client:"
msgstr "我们先初始化API客户端："

#: ../../source/framework/function_call.md:810 fb4c994fb0bf4a5e9141471c2ffead3f
msgid "We can use the create chat completions endpoint to query the model:"
msgstr "我们可以使用create chat completions endpoint直接查询底层API："

#: ../../source/framework/function_call.md:826 f8b65cef89854c1f8487d72ff8b2e1c9
msgid "vLLM should be able to parse the tool calls for us, and the main fields in the response (`response.choices[0]`) should be like"
msgstr "vLLM应当可以为我们解析工具调用，回复的主要字段(`response.choices[0]`)应如下所示："

#: ../../source/framework/function_call.md:853 3fbd1bc39bd84c2695ddbef0379d75b1
msgid "Note that the function arguments are JSON-formatted strings, which Qwen-Agent follows but `transformers` and Ollama differs."
msgstr "请注意这里函数的参数是JSON格式字符串，Qwen-Agent与其一致，但`transformers`和Ollama与之相异。"

#: ../../source/framework/function_call.md:855 17a8fa0d99824fa6a2c2106d50a1d546
msgid "As before, chances are that there are corner cases where tool calls are generated but they are malformed and cannot be parsed. For production code, we should try parsing by ourselves."
msgstr "如前所述，有可能存在边界情况，模型生成了工具调用但格式不良也无法被解析。对于生产代码，我们需要尝试自行解析。"

#: ../../source/framework/function_call.md:858 2a5acfe54c0442bc96d4a03d47a25682
msgid "Then, we can obtain the tool results and add them to the messages as shown below:"
msgstr "随后，我们可以调用工具并获得结果，然后将它们加入消息中："

#: ../../source/framework/function_call.md:879 fee8626898ce4494bcedf74f669c7c66
msgid "It should be noted that the OpenAI API uses `tool_call_id` to identify the relation between tool results and tool calls."
msgstr "这里需要注意OpenAI API使用`tool_call_id`字段来识别工具结果和工具调用间的联系。"

#: ../../source/framework/function_call.md:897 8098b7683d2f42faa5a38a1017f92af9
msgid "Let's call the endpoint again to seed the tool results and get response:"
msgstr "让我们再次查询接口，以给模型提供工具结果并获得回复："

#: ../../source/framework/function_call.md:914 62477b91106f4c9fb8efe3d676203156
#, fuzzy
msgid "The final response (`response.choices[0].message.content`) should be like"
msgstr "最终响应 (`response.choices[0].message`)应如"

#: ../../source/framework/function_call.md:919 b31b9c21a2134fc7ad8c4ab136694c1c
msgid "Discussions"
msgstr "小结"

#: ../../source/framework/function_call.md:921 8e8dbc087bd84cafb22fad9a93eafee1
msgid "Now, we have introduced how to conduct inference with function calling using Qwen2 in three different frameworks! Let's make a brief comparison."
msgstr "现在，我们已经介绍了如何使用Qwen2在三种不同的框架中通过函数调用进行推理！让我们做一个简要的比较。"

#: ../../source/framework/function_call.md:550 41af01996746462d8ec871c0237c8bc0
msgid "Item"
msgstr "项目"

#: ../../source/framework/function_call.md:550 f643fe42f684477aaf0020f7bde22400
msgid "OpenAI API"
msgstr ""

#: ../../source/framework/function_call.md:550 603de33a84184913aea5de774df7536e
msgid "Type"
msgstr "类型"

#: ../../source/framework/function_call.md:550 2f4c13eebb0542b3a10ab20dce93482e
#: 33089855988440f5931f177c6b1c37fe 94e9c6362e1e4352a37f8a23722f1cb1
#: e3aa44af299441a7b3b8a128eab5247f
msgid "HTTP API"
msgstr ""

#: ../../source/framework/function_call.md:550 6ed90bdcf8274aa3b2418a39b6db33f6
#: daf0b5d690b9430888cb228ed5ce98c5
msgid "Python Library"
msgstr "Python库"

#: ../../source/framework/function_call.md:550 62f54834d72e420db689eb04f4c9496f
msgid "Inference Backend"
msgstr "推理后端"

#: ../../source/framework/function_call.md:550 198076ab99e74ed19733c0ca4367ba4c
#: bca7a82908cb4a368666f9d05c10cf2e
msgid "-"
msgstr ""

#: ../../source/framework/function_call.md:550 62db393f0dad429992f8e7260bda028e
#: 8aceb2117fa04d1482b0873936f1310e
msgid "PyTorch"
msgstr ""

#: ../../source/framework/function_call.md:550 cf048a7a8d8d493788c89cf255e79f3f
msgid "llama.cpp"
msgstr ""

#: ../../source/framework/function_call.md:550 cdaf69aecc4346a5864ae4ca6ee2e7e6
msgid "Templating Backend"
msgstr "模板后端"

#: ../../source/framework/function_call.md:550 6205613739564f71853cdbfa3147a235
#: 7654cfb994d3411aa9004054adf3b3f0
msgid "Jinja"
msgstr ""

#: ../../source/framework/function_call.md:550 21d36068eda54cc192090eac85787d03
msgid "Go `text/template`"
msgstr ""

#: ../../source/framework/function_call.md:550 b6416122621e454e897af6d6fcca6abc
msgid "Python"
msgstr ""

#: ../../source/framework/function_call.md:550 13d82541ab33494ea80862352eabc272
msgid "Tools/Functions"
msgstr ""

#: ../../source/framework/function_call.md:550 295b48879b77467e97487bd5780e8577
#: 814f50ecdb344c8fbad472c1a2a543a9 8b92e69ae5104ff9bd2f8791257bd204
#: 9631116c1b8a453ab89a3c3cdb1a72f3
msgid "Tools"
msgstr ""

#: ../../source/framework/function_call.md:550 aef675db85924678893af43b3cdb7459
msgid "Functions"
msgstr ""

#: ../../source/framework/function_call.md:550 be2e7b064ece47f59e233ce98c915f11
msgid "Parallel Calls"
msgstr "并行调用"

#: ../../source/framework/function_call.md:550 11aae8ae6302482787a0087b264a7484
msgid "Default Yes (Configurable)"
msgstr "默认是（可配置）"

#: ../../source/framework/function_call.md:550 1c2a7a43a63d4dab9d3e5ec34056e3b3
#: acfdad0e471741dca25fa56bf8c340f8 cc1175b82d054c64aadc9495af0d6852
msgid "Yes"
msgstr "是"

#: ../../source/framework/function_call.md:550 5786ab36572b4779841bb17974e054f3
msgid "Default No (Configurable)"
msgstr "默认否（可配置）"

#: ../../source/framework/function_call.md:550 8c902bdb085b4a87a11ef5dcac4bfe0f
msgid "Call Format"
msgstr "调用格式"

#: ../../source/framework/function_call.md:550 34b788e5321440c3b7c6ea3f79fee72a
#: 6c7a415e11fd49bb852296defd9cd0bf 9bf7172ed254453e971040a5cd12424c
#: fdbaf1c9edbf4d77ab44547b39b9b108
msgid "Single assistant message with `tool_calls`"
msgstr "带有`tool_calls`的单个助手消息"

#: ../../source/framework/function_call.md:550 828205221c1d45c1b8386d7bb1991640
msgid "Multiple assistant messages with `function_call`"
msgstr "带有`function_call`的多个助手消息"

#: ../../source/framework/function_call.md:550 b9a337ecd3414a2aae7236680827eeb4
msgid "Call Argument Format"
msgstr "调用参数格式"

#: ../../source/framework/function_call.md:550 68c08900f3b34bb390a24a5a96af3e32
#: c2e3e0a1222f495a89d4e0b074d40ea0 de30e6c99012493b83328cb8cda6a6b6
msgid "string"
msgstr ""

#: ../../source/framework/function_call.md:550 3b9588ff30594b208612af3d9cfebc0a
#: e43c9953d49c4a94b4f599c346482902
msgid "object"
msgstr ""

#: ../../source/framework/function_call.md:550 ae67d16d42a84f0f94f422e0b3c1fe24
msgid "Call Result Format"
msgstr "调用结果格式"

#: ../../source/framework/function_call.md:550 004158c969594fcfa2cc5d3c50373a7b
#: 15eec47bc79d4a08b8f547d1a07ae942 652e3411ca7b4e8aaa7ed373751bb55f
#: 7842ded6512b4f70a9c6ee056758f06e
msgid "Multiple tool messages with `content`"
msgstr "带有`content`的多个工具消息"

#: ../../source/framework/function_call.md:550 f9fce980a9264f1bb3c96bfaea7ae80d
msgid "Multiple function messages with `content`"
msgstr "带有`content`的多个函数消息"

#: ../../source/framework/function_call.md:936 872505b60a4440fe905dbd3d986424fb
msgid "There are some details not shown in the above table:"
msgstr "上表中有些特性未被体现："

#: ../../source/framework/function_call.md:937 07563539ede448a688859c83dd7742b8
msgid "OpenAI API comes with Python, Node.js, Go, and .NET SDKs. It also follows the OpenAPI standard."
msgstr "OpenAI API附带了Python、Node.js、Go和.NET SDK。它还遵循OpenAPI标准。"

#: ../../source/framework/function_call.md:938 e0e9046df15044a087a659b31e2da724
msgid "Ollama comes with Python and Node.js SDKs. It has OpenAI-compatible API at a different base url that can be accessed using OpenAI API SDK."
msgstr "Ollama附带了Python和Node.js SDK。它在不同的base URL上具有与OpenAI兼容的API，可以使用OpenAI API SDK访问。"

#: ../../source/framework/function_call.md:939 8f789018b16943c7ba1f4c3cd85d91e6
msgid "Qwen-Agent as an application framework can call the tools automatically for you, which is introduced in [the Qwen-Agent guide](./qwen_agent)."
msgstr "作为应用程序框架，Qwen-Agent可以自动为您调用工具，这在[Qwen-Agent指南](./qwen_agent)中有所介绍。"

#: ../../source/framework/function_call.md:942 b0ebef4947e04cabbaa4a14ecf15e62d
msgid "In addition, there are more on the model side of function calling, which means you may need to consider more things in production code:"
msgstr "此外，在函数调用的模型方面还有更多内容，这意味着您可能需要在生产代码中考虑更多的事情："

#: ../../source/framework/function_call.md:943 9cbc9ae4f13c4d319290fcab44a61b92
msgid "**Accuracy of function calling**: When it comes to evaluate the accuracy of function calling, there are two aspects: (a) whether the correct functions (including no functions) are selected and (b) whether the correct function arguments are generated. It is not always the case that Qwen2.5 will be accurate.  Function calling can involve knowledge that is deep and domain-specific. Sometimes, it doesn't fully understand the function and select the wrong one by mistake. Sometimes, it can fall into a loop and require calling the same function again and again.  Sometimes, it will fabricate required function arguments instead of asking the user for input. To improve the function calling accuracy, it is advised to first try prompt engineering: does a more detailed function description help? can we provide instructions and examples to the model in the system message? If not, finetuning on your own data could also improve performance."
msgstr "**函数调用准确性**：在评估函数调用的准确性时，有两个方面：(a) 是否选择了正确的函数（包括没有函数）以及(b) 是否生成了正确的函数参数。Qwen2.5并不总是准确的。函数调用可能涉及深入且领域特定的知识。有时，它不能完全理解函数并错误地选择了错误的函数。有时，它可能会陷入循环，需要反复调用相同的函数。有时，它会伪造所需的函数参数而不是向用户请求输入。为了提高函数调用的准确性，建议首先尝试提示工程：更详细的函数描述是否有所帮助？我们是否可以在系统消息中为模型提供指导和示例？如果没有，使用自己的数据进行微调也可以提高性能。"

#: ../../source/framework/function_call.md:956 3043f53c507c4031a20497b1561238c8
msgid "**Protocol consistency**: Even with the proper function calling template, the protocol may break. The model may generate extra texts to tool calls, e.g., explanations. The generated tool call may be invalid JSON-formatted string but a representation of a Python dict The generated tool call may be valid JSON but not conforms to the provided JSON Schema. For those kinds of issues, while some of them could be addressed with prompt engineering, some are caused by the nature of LLMs and can be hard to resolve in a general manner by LLMs themselves. While we strive to improve Qwen2.5 in this regard, edge cases are unlikely to be eliminated completely."
msgstr "**协议一致性**：即使具备恰当的函数调用模板，协议也可能被破坏。模型可能会在工具调用中生成额外文本，例如解释说明。生成的工具调用可能是无效的JSON格式字符串，但是是Python dict的字符串表示；生成的工具调用可能是有效的JSON，但不符合提供的JSON Schema。对于这类问题，虽然有些可以通过提示工程解决，但有些是由大型语言模型的本质引起的，很难由大模型本身以通用方式解决。尽管我们在这一方面努力改进Qwen2.5，但极端情况不太可能被完全消除。"

#: ../../source/framework/function_call.md:965 bf0d4ab89eaa43debfc461db2461c406
msgid "Function Calling Templates"
msgstr "函数调用模板"

#: ../../source/framework/function_call.md:967 b22820a2fc4846ab8e4bbc0c3e280c4d
msgid "The template design for function calling often includes the following aspects:"
msgstr "函数调用的模板设计通常包括以下方面："

#: ../../source/framework/function_call.md:968 9fc068e5a8f54df6a88886f5f52b5b3d
msgid "How to describe the functions to the model, so that the model understands what they are and how to use them."
msgstr "如何向模型描述这些函数，以便模型理解它们是什么以及如何使用它们。"

#: ../../source/framework/function_call.md:969 b2e960d178614bd5aa03af3ab732bcac
msgid "How to prompt the model, so that it knows that functions can be used and in what format to generate the function calls."
msgstr "如何提示模型，以便它知道可以使用函数，并以何种格式生成函数调用。"

#: ../../source/framework/function_call.md:970 b5303202c6c6485fa128653efcf43fe6
msgid "How to tell a function call generation from others in generated text, so that we can extract the calls from the generated texts and actually make the calls."
msgstr "如何从生成的文本中区分函数调用与其他内容，以便我们能够从生成的文本中提取调用并实际执行调用。"

#: ../../source/framework/function_call.md:971 c29ac8a5f36c41259de28b4e08c9fa53
msgid "How to incorporate the function results to the text, so that the model can tell them from its own generation and make connection among the calls and the results."
msgstr "如何将函数结果融入文本中，以便模型能够将其与自己的生成区分开来，并在调用和结果之间建立联系。"

#: ../../source/framework/function_call.md:973 f9324ba1c4ae4bc4a0bdd345c245d6cc
msgid "For experienced prompt engineers, it should be possible to make any LLM support function calling, using in-context learning techniques and with representative examples, though with varied accuracy and stability depending on how \"zero-shot\" the task at hand is."
msgstr "对于经验丰富的提示工程师而言，应该有可能利用上下文学习技术和代表性示例，使任何大模型支持函数调用，尽管准确性和稳定性会根据手头任务的“零样本”程度而有所不同。"

#: ../../source/framework/function_call.md:975 554c763946fd40e1bbe5d9caa68460dc
msgid "Starting from ReAct Prompting"
msgstr "从ReAct Prompting开始"

#: ../../source/framework/function_call.md:977 1c52b24d230544a4a93bc8d0d218fc94
msgid "For example, ReAct Prompting can be used to implement function calling with an extra element of planning:"
msgstr "例如，可以使用ReAct Prompting实现带有额外规划元素的函数调用："

#: ../../source/framework/function_call.md:978 2aa42ffaac8b4726a04898302066ab34
msgid "**Thought**: the overt reasoning path, analyzing the functions and the user query and saying it out \"loud\""
msgstr "**Thought**：显而易见的推理路径，分析函数和用户查询，并大声“说”出来"

#: ../../source/framework/function_call.md:979 fe22eb99bdb94be6a58bdfa536b3b39f
msgid "**Action**: the function to use and the arguments with which the function should be called"
msgstr "**Action**：要使用的函数以及调用该函数时应使用的参数"

#: ../../source/framework/function_call.md:980 52cf0261b8e448fdaad8534c40bf1484
msgid "**Observation**: the results of the function"
msgstr "**Observation**：函数的结果"

#: ../../source/framework/function_call.md:982 2d282d96327f4d9884d8bcf812d17921
msgid "In fact, Qwen2 is verse in the following variant of ReAct Prompting (similar to LangChain ReAct) to make the intermediate texts more structured:"
msgstr "实际上，Qwen2熟练掌握以下变体的ReAct Prompting（类似于LangChain ReAct），以使中间文本更具结构化："

#: ../../source/framework/function_call.md:1012
#: 596474fcda7a47fcba527296bf561bbe
msgid "As you can see, there is no apparent user/assistant conversation structure in the template. The model will simply continue the texts. One should write the code to actively detect which step the model is at and in particular to add the observations in the process, until the Final Answer is generated."
msgstr "如您所见，模板中没有明显的用户/助手对话结构。模型将简单地继续文本。应该编写代码来主动检测模型处于哪个步骤，并特别在过程中添加观察结果，直到生成最终答案。"

#: ../../source/framework/function_call.md:1016
#: 774a3900f52048c98b1f21dcca5bb3dd
#, fuzzy
msgid "However, as most programming interfaces accept the message structure, there should be some kind of adapter between the two. [The ReAct Chat Agent](https://github.com/QwenLM/Qwen-Agent/blob/v0.0.10/qwen_agent/agents/react_chat.py) in Qwen-Agent facilitates this kind of conversion."
msgstr "然而，由于大多数编程接口接受“message”结构，两者之间应该有某种适配器。[Qwen-Agent中的ReAct Chat Agent](https://github.com/QwenLM/Qwen-Agent/blob/v0.0.9/qwen_agent/agents/react_chat.py)实现了这种转换。"

#: ../../source/framework/function_call.md:1019
#: ef51677a967b4c34848b10297cef8e87
msgid "Qwen2 Function Calling Template"
msgstr "Qwen2 函数调用模板"

#: ../../source/framework/function_call.md:1021
#: 44695480211b43d2904c21a9cd31c5b7
msgid "As a step forward, the official Qwen2 function calling template is in the vein of the ReAct Prompting format but focuses more on"
msgstr "作为向前迈进的一步，官方的Qwen2函数调用模板沿袭了ReAct Prompting格式，但更侧重于"

#: ../../source/framework/function_call.md:1022
#: 72cb5f2d12464430ae468109de328d86
msgid "differentiating the keywords like `Question`, `Thought`, `Action`, etc., from generation,"
msgstr "将诸如`Question`、`Thought`、`Action`等关键词与生成区分开来，"

#: ../../source/framework/function_call.md:1023
#: d1080dce82464d689f13bcadc1a698d1
msgid "simplifying the process,"
msgstr "简化这一过程，"

#: ../../source/framework/function_call.md:1024
#: 63677f7c7f594047b53b395aefc38aaa
msgid "supporting better multi-turn conversation, and"
msgstr "更好支持多轮对话，以及"

#: ../../source/framework/function_call.md:1025
#: 66d400a715334b03ab328d15e147455c
msgid "adding controls for specialized usage."
msgstr "为特异性使用添加控制。"

#: ../../source/framework/function_call.md:1028
#: e89ae762017c412db73f1120c753ce9a
msgid "An equivalent example would be"
msgstr "一个等效的例子是"

#: ../../source/framework/function_call.md:1060
#: 349decbb6c0f414a96d33164d418e3e9
msgid "Let's first list the obvious differences:"
msgstr "我们先列出明显的差异："

#: ../../source/framework/function_call.md:1061
#: 618fdea619d4468c871fb490429334e7
msgid "Keywords (`✿FUNCTION✿`, `✿ARGS✿`, etc.) seem rare in ordinary text and more semantically related to function calling, but not special tokens yet."
msgstr "关键字（`✿FUNCTION✿`, `✿ARGS✿`等）在普通文本中似乎很少见，且与函数调用语义相关，但尚未成为特殊token。"

#: ../../source/framework/function_call.md:1062
#: bcfcc5d1f6e04cdda658983152d6d439
msgid "Thought is omitted. This could affect accuracy for some use cases."
msgstr "Thought被省略了。这可能会影响某些使用场景的准确性。"

#: ../../source/framework/function_call.md:1063
#: a9b541f2d8c54663b570cb1ac2760f83
msgid "Use the system-user-assistant format for multi-turn conversations. Function calling prompting is moved to the system message."
msgstr "对于多轮对话，请采用系统-用户-助手格式。函数调用提示已移至系统消息中。"

#: ../../source/framework/function_call.md:1065
#: d66120902d81440e8b9adccc4fd00a85
msgid "How about adding controls for specialized usage? The template actually has the following variants:"
msgstr "那对于特异性使用添加的控制呢？实际上，该模板有以下变体："

#: ../../source/framework/function_call.md:1067
#: 22121547a893482d8a345686751ce2f8
msgid "Language: the above is for non-Chinese language; there is another template in Chinese."
msgstr "语言：上述内容适用于非中文；另有一份中文模板。"

#: ../../source/framework/function_call.md:1068
#: 3ef083aeeb2a4bce98027e820c18e264
msgid "Parallel Calls: the above is for non-parallel calls; there is another template for parallel calls."
msgstr "并行调用：上述内容适用于非并行调用；另有一份并行调用的模板。"

#: ../../source/framework/function_call.md:1070
#: 6fca464301064da183285585ca1ed7b7
msgid "In the canonical implementation in Qwen-Agent, those switches are implemented in Python, according to the configuration and current input."
msgstr "在Qwen-Agent的标准实现中，这些开关是根据配置和当前输入，用Python实现的。"

#: ../../source/framework/function_call.md:1072
#: 527f090c195b4b61bbcb369ea74703af
#, fuzzy
msgid "The actual text with _parallel calls_ should be like the following:"
msgstr "带有并行调用的实际文本应如下所示："

#: ../../source/framework/function_call.md:1118
#: 92147360275a499a83c3147232c9bc5a
#, fuzzy
msgid "This template is hard to adapt it for other frameworks that use less capable templating engines. But it is doable at least partially for Jinja, which is Python-oriented after all. We didn't use it because using the template in `transformers` leads to more changes to the inference usage, which are not very common for beginners."
msgstr "[之前](#note-official-template)，我们说过，Qwen2的函数调用模板很难为使用功能较弱模板引擎的其他框架进行适应。但至少部分地，对于Jinja（毕竟它是面向Python的）来说是可行的。我们没有使用它，因为在`transformers`中使用模板会导致对推理使用的更多变更，而这对于初学者来说并不常见。"

#: ../../source/framework/function_call.md:1122
#: 9d88afabaa324b63b92eb6e848017388
msgid "For the interested, you can find the Jinja template and key points on usage below:"
msgstr "对于有兴趣的人，您可以在下方找到Jinja模板及其使用要点："

#: ../../source/framework/function_call.md eaf165f4ec694e019d67e91182c92965
msgid "Qwen2 Function Calling Jinja Template"
msgstr "Qwen2 函数调用Jinja模板"

#: ../../source/framework/function_call.md:1195
#: 080b3359233741e7b98f4ef6203f3639
msgid "To use this template in `transformers`:"
msgstr "要在`transformers`中使用此模板："

#: ../../source/framework/function_call.md:1197
#: d921f36e8f7c438ead91295b0dadc095
msgid "Switches can be enabled by passing them to the `apply_chat_template` method, e.g., `tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=True, parallel_tool_call=True, language=\"zh\", tokenize=False)`. By default, it is for English non-parallel function calling."
msgstr "可以通过将它们传递给`apply_chat_template`方法来启用开关，例如，`tokenizer.apply_chat_template(messages, tools=tools, add_generation_prompt=True, parallel_tool_call=True, language=\"zh\", tokenize=False)`。默认情况下，这是用于英语非并行函数调用。"

#: ../../source/framework/function_call.md:1199
#: 17a6dc607b1a4948accd09e663150a63
#, fuzzy
msgid "The tool arguments should be a Python `dict` instead of a JSON-formatted object `str`."
msgstr "如果函数参数是有效的JSON格式字符串，则将其解析为字典。"

#: ../../source/framework/function_call.md:1201
#: 5ae533a6978549f2945534e8d13e09ca
msgid "Since the generation needs to be stopped at `✿RESULT✿` or else the model will generate fabricated tool results, we should add it to `stop_strings` in `generation_config`:"
msgstr "由于生成需要在遇到`✿RESULT✿`时停止，不然模型会继续生成编造的工具结果，我们需要将这些字符串加到`generation_config`中的`stop_strings`字段："

#: ../../source/framework/function_call.md:1206
#: 23630877396a4fa695d4e036864c1efc
msgid "As a result of using `stop_strings`, you need to pass the tokenizer to `model.generate` as `model.generate(**inputs, tokenizer=tokenizer, max_new_tokens=512)`."
msgstr "由于使用了`stop_strings`，您需要将tokenizer传递给`model.generate`，即`model.generate(**inputs, tokenizer=tokenizer, max_new_tokens=512)`。"

#: ../../source/framework/function_call.md:1208
#: bb17a1c75f334e688c0ab7b1050ba51a
msgid "`response`, i.e., the model generation based on the tool calls and tool results, may contain a leading space. You should not strip it for the model. It is resulted from the tokenization and the template design."
msgstr "基于工具调用和工具结果的模型生成，即`response`，可能包含一个前导空格。作为后续消息输入模型时，不要碰这个空格。这是由tokenization和模板设计导致的。"

#: ../../source/framework/function_call.md:1210
#: 3db08f76891d49058587ccfd0bddc096
msgid "The `try_parse_tool_calls` function should also be modified accordingly."
msgstr "`try_parse_tool_calls`函数也应进行相应的修改。"

#: ../../source/framework/function_call.md:1214
#: 9f9264c714eb4aacb56b5c5789deb5fa
msgid "Qwen2.5 Function Calling Templates"
msgstr "Qwen2.5 函数调用模板\""

#: ../../source/framework/function_call.md:1216
#: eb475f48fa0c4a38adb298f47096c313
msgid "For `transformers` and Ollama, we have also used templates that are easier to implement with Jinja or Go. They are variants of [the Nous Research's Hermes function calling template](https://github.com/NousResearch/Hermes-Function-Calling#prompt-format-for-function-calling). The Jinja template and the Go template should produce basically the same results. They final text should look like the following:"
msgstr "对于`transformers`和Ollama，我们也使用易于Jinja和Go实现的模板，它们是[Nous Research的Hermes函数调用模板](https://github.com/NousResearch/Hermes-Function-Calling#prompt-format-for-function-calling)的变体。Jinja模板和Go模板应基本产生相同的结果。最终文本应如下所示："

#: ../../source/framework/function_call.md:1261
#: aa9e42cf11c44fcda378977abd25d734
msgid "While the text may seem different from the previous one, the basic prompting structure is still the same. There are just more structural tags and more JSON-formatted strings."
msgstr "虽然文本可能与官方的有所不同，但基本的提示结构仍然相同。只是有更多结构标签和更多JSON格式的字符串。"

#: ../../source/framework/function_call.md:1266
#: 31003ebe1abf40d78ebbe1976d405a05
msgid "There is one thing we haven't talked about: how should functions be described to the LLMs. In short, you could describe them as you would normally describe them in an API documentation, as long as you can effectively parse, validate, and execute the tool calls generated by the models. The format with JSON Schema appears a valid and common choice."
msgstr "有一件事我们尚未提及：如何向大型语言模型描述函数。简而言之，你可以像在API文档中通常描述它们那样来描述它们，只要你能有效地解析、验证并执行由模型生成的工具调用。带有JSON Schema的格式似乎是一个有效且常见的选择。"

#: ../../source/framework/function_call.md:1271
#: 388334302ac04a858df0c8ff46d0f9da
msgid "Finally"
msgstr "最后"

#: ../../source/framework/function_call.md:1273
#: c2d371071ad04a22affd23e381baa182
msgid "In whichever way you choose to use function calling with Qwen2.5, keep in mind that the limitation and the perks of prompt engineering applies:"
msgstr "无论你选择哪种方式在Qwen2.5中使用函数调用，请记住提示工程的限制和优势适用："

#: ../../source/framework/function_call.md:1274
#: 25b5a112d09e4d399c267bceedb1a957
msgid "It is not guaranteed that the model generation will always follow the protocol even with proper prompting or templates. Especially, for the templates that are more complex and relies more on the model itself to think and stay on track than the ones that are simpler and relies on the template and the use of control or special tokens. The latter one, of course, requires some kind of training. In production code, be prepared that if it breaks, countermeasures or rectifications are in place."
msgstr "无法保证模型生成将始终遵循协议，即使有适当的提示或模板。特别是对于那些更复杂且更多依赖于模型本身思考和保持方向的模板，而非那些更简单且依赖于模板以及控制或特殊标记使用的模板。当然，后者需要某种训练。在生产代码中，要准备好如果出现问题，采取补救措施或修正措施。"

#: ../../source/framework/function_call.md:1278
#: f1591e6b818a4ef1887d9c7e42993a6e
msgid "If in certain scenarios, the generation is not up to expectation, you can refine the template to add more instructions or constraints. While the templates mentioned here are general enough, they may not be the best or the most specific or the most concise for your use cases. The ultimate solution is fine-tuning using your own data."
msgstr "如果在某些场景下，生成结果未达到预期，你可以细化模板以添加更多指令或约束。尽管这里提到的模板足够通用，但对于你的具体使用案例，它们可能不是最佳的、最具体的或最简洁的。最终解决方案是使用你自己的数据进行微调。"

#: ../../source/framework/function_call.md:1282
#: d65f4fcdebad481cb1a91bdb8238a760
msgid "Have fun prompting!"
msgstr "享受提示的乐趣吧！"

#: ../../source/framework/function_call.md:480 853258b2238a4b7393c4007b9b91b33c
msgid "`transformers` will use `transformers.utils.get_json_schema` to generate the tool descriptions from Python functions. There are some gotchas with `get_json_schema`, and it is advised to check [its doc \\[v4.44.2\\]](https://github.com/huggingface/transformers/blob/v4.44.2/src/transformers/utils/chat_template_utils.py#L183-L288) before relying on it."
msgstr "`transformers`将使用`transformers.utils.get_json_schema`从Python函数生成工具描述。`get_json_schema`存在一些陷阱，在依赖它之前建议查看[其文档\\[v4.44.2\\]](https://github.com/huggingface/transformers/blob/v4.44.2/src/transformers/utils/chat_template_utils.py#L183-L288)。"

#: ../../source/framework/function_call.md:483 821a2838cb3940248600e1be1c6904a4
msgid "The function should use Python type hints for parameter types and has a Google-style docstring for function description and parameter descriptions."
msgstr "函数应使用Python类型注释表示参数类型，并具有Google风格的docstring用于函数描述和参数描述。"

#: ../../source/framework/function_call.md:484 59c7469971ee4af9b47746492414e3e4
msgid "Supported types are limited, since the types needs to be mapped to JSON Schema. In particular, `typing.Literal` is not supported. You can instead add `(choices: ...)` at the end of a parameter description, which will be mapped to a `enum` type in JSON Schema."
msgstr "支持的类型有限，因为这些类型需要映射到JSON Schema。特别是，`typing.Literal`不受支持。你可以在参数描述的末尾添加`(choices: ...)`，这将在JSON Schema中映射为`enum`类型。"

#: ../../source/framework/function_call.md:488 c4c4f56df54f443b804c3d2e877a278e
msgid "Please be aware that all the returned results in the examples in the linked docstring are actually the content of the `function` field in the actual returned results."
msgstr "请注意，链接docstring中的所有返回结果示例实际上是实际返回结果中`function`字段的内容。"

#~ msgid "In `transformers`, the tool calls should be a field of assistant messages.[^tool_call_arg_format] Let's use a simple function called `try_parse_tool_calls` to parse the tool calls, which can be found in [the preparation code](#prepcode). This function does not cover all possible scenarios and thus is prone to errors. But it should suffice for the purpose of this guide."
#~ msgstr "在`transformers`中，工具调用应该是助手消息的一个字段[^tool_call_arg_format]。让我们使用一个简单的函数`try_parse_tool_calls`来解析工具调用，该函数可以在[准备代码](#prepcode)中找到。此函数并未涵盖所有可能场景，因此容易出错。但对于本指南的目的而言，它应该足够了。"

#~ msgid "However, note that the model generates arguments in tool calls not as a JSON object but a JSON-formatted string of the JSON object.  For `transformers` and `ollama`, as the interfaces require the arguments to be JSON objects or Python dicts, there will be differences between the actual model generation and the template results for tool call arguments."
#~ msgstr "然而，请注意，模型在工具调用中生成的参数不是作为JSON对象，而是该JSON对象的JSON格式字符串。对于`transformers`和`ollama`，由于接口要求参数为JSON对象或Python字典，因此实际模型生成和模板结果之间的工具调用参数格式将存在差异。"

