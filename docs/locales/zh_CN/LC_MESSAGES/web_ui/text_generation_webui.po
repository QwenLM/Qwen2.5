# Copyright (C) 2024, Qwen Team, Alibaba Group.
# This file is distributed under the same license as the Qwen package.
#
msgid ""
msgstr ""
"Project-Id-Version: Qwen \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-08-08 19:58+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../../source/web_ui/text_generation_webui.rst:2
#: 17cad91e01fe478c8304e95600efbea7
msgid "Text Generation Web UI"
msgstr "Text Generation Web UI"

#: ../../source/web_ui/text_generation_webui.rst:4
#: a5a5da61c02e45f58441a48f4181d8ec
msgid ""
"`Text Generation Web UI <https://github.com/oobabooga/text-generation-"
"webui>`__ (TGW, or usually referred to \"oobabooga\") is a popular web UI"
" for text generation, similar to `AUTOMATIC1111/stable-diffusion-webui "
"<https://github.com/AUTOMATIC1111/stable-diffusion-webui>`__. It has "
"multiple interfaces, and supports multiple model backends, including "
"`Transformers <https://github.com/huggingface/transformers>`__, "
"`llama.cpp <https://github.com/ggerganov/llama.cpp>`__ (through `llama-"
"cpp-python <https://github.com/abetlen/llama-cpp-python>`__), `ExLlamaV2 "
"<https://github.com/turboderp/exllamav2>`__, `AutoGPTQ "
"<https://github.com/PanQiWei/AutoGPTQ>`__, `AutoAWQ <https://github.com"
"/casper-hansen/AutoAWQ>`__, `GPTQ-for-LLaMa "
"<https://github.com/qwopqwop200/GPTQ-for-LLaMa>`__, `CTransformers "
"<https://github.com/marella/ctransformers>`__, `QuIP# <https://github.com"
"/Cornell-RelaxML/quip-sharp>`__. In this section, we introduce how to run"
" Qwen locally with TGW."
msgstr ""
"`Text Generation Web UI <https://github.com/oobabooga/text-generation-"
"webui>`__ （简称TGW，通常被称为“oobabooga”）是一款流行的文本生成Web界面工具，类似于 `AUTOMATIC1111"
"/stable-diffusion-webui <https://github.com/AUTOMATIC1111/stable-"
"diffusion-webui>`__ 。它拥有多个交互界面，并支持多种模型后端，包括 `Transformers "
"<https://github.com/huggingface/transformers>`__ 、 `llama.cpp "
"<https://github.com/ggerganov/llama.cpp>`__ （通过 `llama-cpp-python "
"<https://github.com/abetlen/llama-cpp-python>`__ 实现）、 `ExLlamaV2 "
"<https://github.com/turboderp/exllamav2>`__ 、 `AutoGPTQ "
"<https://github.com/PanQiWei/AutoGPTQ>`__ 、 `AutoAWQ <https://github.com"
"/casper-hansen/AutoAWQ>`__ 、 `GPTQ-for-LLaMa "
"<https://github.com/qwopqwop200/GPTQ-for-LLaMa>`__ 、 `CTransformers "
"<https://github.com/marella/ctransformers>`__ 以及 `QuIP# "
"<https://github.com/Cornell-RelaxML/quip-sharp>`__ "
"。在本节中，我们将介绍如何在本地环境中使用TGW运行Qwen。"

#: ../../source/web_ui/text_generation_webui.rst:23
#: 26bce3f84a574b0091802f7ed3d04694
msgid "Quickstart"
msgstr "快速开始"

#: ../../source/web_ui/text_generation_webui.rst:25
#: 35a47bc0147e43329284d5d20281cfe1
msgid ""
"The simplest way to run TGW is to use the provided shell scripts in the "
"`repo <https://github.com/oobabooga/text-generation-webui>`__. For the "
"first step, clone the repo and enter the directory:"
msgstr ""
"最简单的运行TGW（Text Generation WebUI）的方法是使用 `repo "
"<https://github.com/oobabooga/text-generation-webui>`__ "
"中提供的Shell脚本。首先，克隆repo并进去文件夹中："

#: ../../source/web_ui/text_generation_webui.rst:34
#: 0ff92b4b26e74df8a26f4a39c5f0036e
msgid ""
"You can directly run the ``start_linux.sh``, ``start_windows.bat``, "
"``start_macos.sh``, or ``start_wsl.bat`` script depending on your OS. "
"Alternatively you can manually install the requirements in your conda "
"environment. Here I take the practice on MacOS as an example."
msgstr ""
"你可以根据你的操作系统直接运行相应的脚本，例如在Linux系统上运行 ``start_linux.sh`` ，在Windows系统上运行 "
"``start_windows.bat`` ，在MacOS系统上运行 ``start_macos.sh`` "
"，或者在Windows子系统Linux（WSL）上运行 ``start_wsl.bat`` "
"。另外，你也可以选择手动在conda环境中安装所需的依赖项。这里以MacOS系统为例进行实践操作。"

#: ../../source/web_ui/text_generation_webui.rst:45
#: 9046c24b86b84dfc8844f1d10ae64146
msgid ""
"Then you can install the requirements by running ``pip install -r`` based"
" on your OS, e.g.,"
msgstr "接下来，您可以根据您的操作系统执行 ``pip install -r`` 命令来安装相应的依赖项，例如，"

#: ../../source/web_ui/text_generation_webui.rst:52
#: 47fc55c698fc4ecb9d69ef8d1c2823a0
msgid ""
"For ``bitsandbytes`` and ``llama-cpp-python`` inside the requirements, I "
"advise you to install them through ``pip`` directly. However, temporarily"
" please do not use GGUF as the performance with TGW is unsatisfactory. "
"After finishing the installation of required packages, you need to "
"prepare your models by putting the model files or directories in the "
"folder ``./models``. For example, you should put the transformers model "
"directory of ``Qwen2-7B-Instruct`` in the way shown below:"
msgstr ""
"对于requirements中的 ``bitsandbytes`` 和 ``llama-cpp-python`` ，我建议您直接通过 "
"``pip`` "
"进行安装。但是，暂时请不要使用GGUF，因为其与TGW配合时的性能表现不佳。在完成所需包的安装之后，您需要准备模型，将模型文件或目录放在 "
"``./models`` 文件夹中。例如，您应按照以下方式将 ``Qwen2-7B-Instruct`` "
"的transformers模型目录放置到相应位置。"

#: ../../source/web_ui/text_generation_webui.rst:76
#: 31ddc7d4ebe6407e9eaa8bd81584e61e
msgid "Then you just need to run"
msgstr "随后你需要运行"

#: ../../source/web_ui/text_generation_webui.rst:82
#: 3f094e9fb18d42e7b3fcb602587335fb
msgid "to launch your web UI service. Please browse to"
msgstr "来启动你的网页服务。请点击进入"

#: ../../source/web_ui/text_generation_webui.rst:88
#: 9f94b143bc72437e91713b52b51d46db
msgid "and enjoy playing with Qwen in a web UI!"
msgstr "然后享受使用Qwen的Web UI吧！"

#: ../../source/web_ui/text_generation_webui.rst:91
#: a86604d7409944bfb2e45b55bffc8532
msgid "Next Step"
msgstr "下一步"

#: ../../source/web_ui/text_generation_webui.rst:93
#: a79b8e62f0fb489ab2c58042c94b8d60
msgid ""
"There are a lot more usages in TGW, where you can even enjoy role play, "
"use different types of quantized models, train LoRA, incorporate "
"extensions like stable diffusion and whisper, etc. Go to figure out more "
"advanced usages and apply them to Qwen models!"
msgstr ""
"TGW 中包含了许多更多用途，您甚至可以在其中享受角色扮演的乐趣，并使用不同类型的量化模型。您可以训练诸如LoRA这样的算法，并将Stable "
"Diffusion和Whisper等扩展功能纳入其中。赶快去探索更多高级用法，并将它们应用于Qwen模型中吧！"

