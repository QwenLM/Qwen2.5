# Copyright (C) 2024, Qwen Team
# This file is distributed under the same license as the Qwen package.
#
msgid ""
msgstr ""
"Project-Id-Version: Qwen \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-13 17:22+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/training/ms_swift.md:1 498aef3956544f9b97c7a47c66997ea2
msgid "MS-SWIFT"
msgstr "MS-SWIFT"

#: ../../source/training/ms_swift.md:3 0a0330c78d8549d1be55501fdc352a15
msgid "ModelScope SWIFT (**ms-swift**) is the large model and multimodal large model training and deployment framework provided by the [ModelScope community](https://modelscope.cn/)."
msgstr "ModelScope SWIFT (**ms-swift**) 是由 `ModelScope 社区 [ModelScope community](https://modelscope.cn/) 提供的大模型和多模态大模型训练部署框架。"

#: ../../source/training/ms_swift.md:5 6e980c27ae67400ca12c11fedf439af8
msgid "GitHub repository: [ms-swift](https://github.com/modelscope/ms-swift)"
msgstr "GitHub 仓库：[ms-swift](https://github.com/modelscope/ms-swift)"

#: ../../source/training/ms_swift.md:7 43999693226b4bc1ba78d7f8addaa01d
msgid "Features of using ms-swift for training LLM:"
msgstr "使用 ms-swift 训练大语言模型的特性："

#: ../../source/training/ms_swift.md:9 b76a71cc42244cccaf2b699e41ee9c7f
msgid "**Model Types**: Supports 500+ plain-text large models and 200+ multimodal large models, covering the entire process from training to deployment."
msgstr "**模型类型**：支持 500+ 纯文本大模型和 200+ 多模态大模型，覆盖从训练到部署全流程。"

#: ../../source/training/ms_swift.md:10 f9a00d8a4789418abc700fd6774d784b
msgid "**Hardware Support**: Compatible with CPUs, RTX series GPUs, T4/V100, A10/A100/H100, Ascend NPUs, MPS, and more."
msgstr "**硬件支持**：兼容 CPU、RTX 系列 GPU、T4/V100、A10/A100/H100、Ascend NPU、MPS 等。"

#: ../../source/training/ms_swift.md:11 ead5a56786bf46b3a94582164537526a
msgid "**Training Methods**: Supports full-parameter fine-tuning, LoRA, QLoRA, DoRA, and other techniques."
msgstr "**训练方法**：支持全参数微调、LoRA、QLoRA、DoRA 等技术。"

#: ../../source/training/ms_swift.md:12 31ad671d19de412e9ad5dd76b933e615
msgid "**Distributed Training**: Supports distributed training technologies such as DDP, device_map, DeepSpeed ZeRO-2/ZeRO-3, FSDP, and integrates parallelism techniques from Megatron, including Tensor Parallelism, Pipeline Parallelism, Sequence Parallelism, and Expert Parallelism."
msgstr "**分布式训练**：支持分布式训练技术，如 DDP、device_map、DeepSpeed ZeRO-2/ZeRO-3、FSDP，并集成 Megatron 的并行技术，包括张量并行、流水线并行、序列并行和专家并行。"

#: ../../source/training/ms_swift.md:13 0d6d437bf4fb4485ba4a3b1ad166558e
msgid "**RLHF Training**: Supports human alignment methods like DPO, GRPO, DAPO, RM, PPO, KTO, etc., for both plain-text and multimodal large models."
msgstr "**RLHF 训练**：支持纯文本和多模态大模型的人类对齐方法，如 DPO、GRPO、DAPO、RM、PPO、KTO 等。"

#: ../../source/training/ms_swift.md:15 76bf873aaf8f495ca929ae422763046b
msgid "This article will demonstrate runnable training demos and provide the format for custom datasets. It includes how to use ms-swift for SFT and GRPO on Qwen3-8B, as well as using Megatron-SWIFT (ms-swift's integration of Megatron-LM) for SFT on Qwen3-30B-A3B. Through expert parallelism technology, MoE model training can be accelerated by nearly 10 times."
msgstr "本文将介绍可运行的训练示例，并提供自定义数据集的格式。内容包括如何使用 ms-swift 对 Qwen3-8B 进行 SFT 和 GRPO，以及使用 Megatron-SWIFT（ms-swift 集成的 Megatron-LM）对 Qwen3-30B-A3B 进行 SFT。通过专家并行技术，MoE 模型的训练速度可以提升近 10 倍。"

#: ../../source/training/ms_swift.md:17 1d166ff43c03452780ae38d1c6cd91e9
msgid "Before starting fine-tuning, ensure your environment is properly set up."
msgstr "在开始微调之前，请确保您的环境已正确配置。"

#: ../../source/training/ms_swift.md:32 8b5caa854cf641c489310f747ed205ba
msgid "Supervised Fine-Tuning (SFT)"
msgstr "监督微调 (SFT)"

#: ../../source/training/ms_swift.md:34 ../../source/training/ms_swift.md:206
#: 4ec49f5d7a1b4a9a9851cafafe9c7623
msgid "Data Preparation"
msgstr "数据准备"

#: ../../source/training/ms_swift.md:36 c71be51476e04ab0884cd908b042e263
msgid "The custom dataset format for SFT using ms-swift is as follows (the system field is optional). You can organize it into formats such as JSON, JSONL, or CSV. Specify `--dataset <dataset_path>` in the training script."
msgstr "使用 ms-swift 进行 SFT 的自定义数据集格式如下（system 字段是可选的）。您可以将其组织为 JSON、JSONL 或 CSV 格式。在训练脚本中指定 `--dataset <dataset_path>`。"

#: ../../source/training/ms_swift.md:38 5de2bd424af14c52b7d73385caca6fba
msgid "For complete dataset formatting guidelines, see: [Custom Dataset Documentation](https://swift.readthedocs.io/en/latest/Customization/Custom-dataset.html)"
msgstr "有关完整的数据集格式指南，请参考[自定义数据集文档](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86.html)。"

#: ../../source/training/ms_swift.md:40 a6a72b65b49f4aa2948a3092e070bee9
msgid "General format"
msgstr "通用格式"

#: ../../source/training/ms_swift.md:48 3e18752803b24196a4e2e307f2418469
msgid "Format with think"
msgstr "带有思考内容格式"

#: ../../source/training/ms_swift.md:56 48aafb23741045c49e62aa67837ebb28
msgid "If you want to train using data without a chain of thought but retain the model's reasoning ability, there are two approaches to minimize disruption during fine-tuning:"
msgstr "如果您想使用不含思维链的数据进行训练，同时保留模型的推理能力，可以通过以下两种方法尽量减少微调期间的干扰："

#: ../../source/training/ms_swift.md:58 ff2352eac1fd4e57987b02b2b2b294e4
msgid "**Option 1**: During training, specify `--loss_scale ignore_empty_think` to ignore the loss calculation for `<think>\\n\\n</think>\\n\\n`, preventing the loss of reasoning ability. Refer to the training script [here](https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo1.sh). The custom dataset format is as follows:"
msgstr "**选项 1**：在训练期间，指定 `--loss_scale ignore_empty_think`，以忽略对 `<think>\\n\\n</think>\\n\\n` 的损失计算，从而避免推理能力的丧失。训练脚本请参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo1.sh)。自定义数据集格式如下："

#: ../../source/training/ms_swift.md:67 fb0799da5fad46129d4682ffb2003f8e
msgid "**Option 2**: Add `/no_think` to the query in the dataset to avoid the loss of reasoning ability. Refer to the training script [here](https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo2.sh). The custom dataset format is as follows:"
msgstr "**选项 2**：在数据集的查询中添加 `/no_think`，以避免推理能力的丧失。训练脚本请参考[这里](https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo2.sh)。自定义数据集格式如下："

#: ../../source/training/ms_swift.md:76 70f3b79067e34c989d6c3235179eff69
msgid "30-Minute Self-Cognition Fine-Tuning"
msgstr "30分钟自我认知微调"

#: ../../source/training/ms_swift.md:78 371e5bc107494dcd90a52569328a520d
msgid "This section introduces a 30-minute self-cognition fine-tuning process for the Qwen3-8B model. The required GPU memory is 22GB, and it can be run on the A10 provided by [ModelScope's free compute resources](https://modelscope.cn/my/mynotebook)."
msgstr "本节将介绍30分钟对 Qwen3-8B 进行自我认知微调。所需GPU显存为 22GB，可以在 ModelScope 提供的[免费算力](https://modelscope.cn/my/mynotebook) A10 中运行。"

#: ../../source/training/ms_swift.md:80 18dff1bfb142418c85d00c3a2f520661
msgid "After training, the model will identify itself as \"swift-robot,\" trained by \"swift,\" instead of its original self-cognition as \"Qwen,\" trained by Alibaba Cloud."
msgstr "训练后，模型将不再认为自己是由“阿里云”训练的“Qwen”，而是由“swift”训练的“swift-robot”。"

#: ../../source/training/ms_swift.md:82 2bf7287254bb432b9c29adc4f79014de
msgid "If you need to train in an offline environment, you can manually download the model and dataset and specify `--model <model-path>` and `--dataset <dataset-dir>`. The dataset can be found on [Modelscope Hub](https://modelscope.cn/datasets/swift/self-cognition)."
msgstr "如果需要在离线环境下进行训练，可以手动下载模型和数据集，并指定 `--model <model-path>` 和 `--dataset <dataset-dir>`。数据集可以在 [Modelscope Hub](https://modelscope.cn/datasets/swift/self-cognition) 上找到。"

#: ../../source/training/ms_swift.md:84 b4dcc1d366304d0abbfa994d76646547
msgid "For the meaning of each parameter in the training script, please refer to the [Command-line parameters documentation](https://swift.readthedocs.io/en/latest/Instruction/Command-line-parameters.html)."
msgstr "关于训练脚本中各参数的含义，请参考[命令行参数文档](https://swift.readthedocs.io/en/latest/Instruction/Command-line-parameters.html)。"

#: ../../source/training/ms_swift.md:114 185248e719634f389f7e85be89cbe7d0
msgid "After fine-tuning, you can use the following script to test the fine-tuning results. Note that the `--adapters` section needs to be modified to the directory path of the last saved checkpoint:"
msgstr "微调完成后，可以使用以下脚本来测试微调结果。注意，`--adapters` 部分需要修改为最后保存检查点的目录路径："

#: ../../source/training/ms_swift.md:134 dd18bd5b0c9d4c8094e6b2c0b6c17ddc
msgid "By default, ms-swift will use the ModelScope community to download models and datasets. If you want to use the HuggingFace community, you need to additionally specify `--use_hf true`."
msgstr "默认情况下，ms-swift 会使用 ModelScope 社区下载模型和数据集。如果想使用 HuggingFace 社区，则需要额外指定 `--use_hf true`。"

#: ../../source/training/ms_swift.md:136 0ad518fadd134498ad3a393397c6d2ae
msgid "Merge LoRA weights:"
msgstr "合并 LoRA 权重："

#: ../../source/training/ms_swift.md:144 4c72b93b992a40d89d27857096f9ac94
msgid "Push the model to ModelScope/HuggingFace:"
msgstr "推送模型到 ModelScope/HuggingFace："

#: ../../source/training/ms_swift.md:157 a10da08e671a464fa20ec51056dd16ef
msgid "If you want to use multiple GPUs for training, the following provides a demo for multi-GPU training:"
msgstr "如果要使用多 GPU 进行训练，以下提供了多 GPU 训练的示例："

#: ../../source/training/ms_swift.md:191 a287c14468ed4625ad50eb75770e4481
msgid "Reinforcement Learning (RL)"
msgstr ""

#: ../../source/training/ms_swift.md:193 007251dabc634a469f47dbdc443f44e5
msgid "ms-swift supports RLHF methods such as DPO, GRPO, DAPO, PPO, KTO, and more. This section will focus on an example of using ms-swift to perform GRPO training for Qwen3-8B."
msgstr "ms-swift 支持 DPO、GRPO、DAPO、PPO、KTO 等 RLHF 方法。本章将着重介绍使用 ms-swift 对 Qwen3-8B 进行 GRPO 训练。"

#: ../../source/training/ms_swift.md:195 6747ebd5490a42fa9bbe39c71d42de64
msgid "For detailed RLHF support information, please refer to: [Supported Features](https://swift.readthedocs.io/en/latest/Instruction/Pre-training-and-Fine-tuning.html)."
msgstr "有关详细的 RLHF 支持信息，请参考[支持的功能](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%BE%AE%E8%B0%83.html)。"

#: ../../source/training/ms_swift.md:197 c40c7e8842a94cf7b8abb7006010b343
msgid "Environment Setup"
msgstr "环境设置"

#: ../../source/training/ms_swift.md:199 b397dfabde0c4e099cb07fd0c3ab6630
msgid "In addition to installing the ms-swift related dependencies introduced above, the following dependencies also need to be installed:"
msgstr "除了安装上述介绍的 ms-swift 相关依赖项外，还需要安装以下依赖项："

#: ../../source/training/ms_swift.md:208 06221d66d22741b49bb4ef2831dc0242
msgid "The dataset format for GRPO training using ms-swift is similar to that of SFT, except that the assistant part of the last round is not required. If using accuracy as a reward, a `solution` column is needed to calculate the accuracy."
msgstr "使用 ms-swift 进行 GRPO 训练的数据集格式与 SFT 类似，但不需要最后一轮的 assistant 部分。如果使用 accuracy 作为奖励，则需要一个 `solution` 列来计算准确率。"

#: ../../source/training/ms_swift.md:210 fb274880c62c4cad8243cbbed73f2adc
msgid "Example Dataset Formats:"
msgstr "示例数据集格式："

#: ../../source/training/ms_swift.md:218 5de2bd424af14c52b7d73385caca6fba
msgid "For dataset preparation for other RLHF algorithms, see: [Custom Dataset Documentation](https://swift.readthedocs.io/en/latest/Customization/Custom-dataset.html#rlhf)."
msgstr "关于其他 RLHF 算法的数据集准备，请参考[自定义数据集文档](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86.html#rlhf)。"

#: ../../source/training/ms_swift.md:220 31d062ff29e14c53ad92ca6d5ab81c23
msgid "Notes on Dataset Requirements:"
msgstr "数据集要求的注意事项："

#: ../../source/training/ms_swift.md:222 f6e1dbba72e9450984df10e9da1f4f4c
msgid "**Reward Function Calculation**: The dataset format depends on the reward function being used. Additional columns may be required to support specific reward calculations. For instance:"
msgstr "**奖励函数计算**：数据集格式取决于所使用的奖励函数。可能需要额外的列来支持特定的奖励计算。例如："

#: ../../source/training/ms_swift.md:224 5b6d41c5b1734f1a87358fb5416c5888
msgid "When using the built-in accuracy or cosine similarity reward, the dataset must include a `solution` column to calculate the accuracy of the responses."
msgstr "当使用内置的 accuracy 或 cosine 奖励时，数据集必须包含一个 `solution` 列以计算回复的准确性。"

#: ../../source/training/ms_swift.md:225 e1937a75effa48ffb42a3d463926c1b0
msgid "Other columns in the dataset will be passed as `**kwargs` to the reward function for additional customization."
msgstr "数据集中的其他列将作为 `**kwargs` 传递给奖励函数以实现进一步的自定义。"

#: ../../source/training/ms_swift.md:227 63ee17a7a6b041a88daee17b96928659
msgid "**Customizing the Reward Function**: To adapt the reward function to your specific needs, you can refer to the following resource: [External Reward Plugin](https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin). This plugin provides examples and templates for implementing custom reward functions."
msgstr "**自定义奖励函数**：为了根据您的具体需求调整奖励函数，可以参考链接[外部奖励插件](https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin)。该插件提供了实现自定义奖励函数的示例和模板。"

#: ../../source/training/ms_swift.md:229 05da2d673c94453cb2bee6c99e46c825
msgid "During the training process, we use vLLM to accelerate the sampling process. By setting `num_infer_workers=8`, we deploy a vLLM engine for each device to speed up the sampling process."
msgstr "在训练过程中，我们使用 vLLM 加速采样过程。通过设置 `num_infer_workers=8` ，我们为每个设备部署一个 vLLM 引擎以加快采样速度。"

#: ../../source/training/ms_swift.md:270 5fe351e5c4f84018988f72da7c78005a
msgid "Megatron-SWIFT"
msgstr "Megatron-SWIFT"

#: ../../source/training/ms_swift.md:272 b4dcc1d366304d0abbfa994d76646547
msgid "ms-swift incorporates Megatron parallelism techniques to accelerate the training of large models. The supported models can be found in the [Supported Models Documentation](https://swift.readthedocs.io/en/latest/Instruction/Supported-models-and-datasets.html)."
msgstr "ms-swift 引入了 Megatron 并行技术以加速大模型的训练。支持的模型可以在[支持的模型文档](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86.html)中找到。"

#: ../../source/training/ms_swift.md:274 cacc805e7bae4869b249768ba0807ae1
msgid "For environment preparation and the conversion between HF and MCore model weights, you can refer to the [Megatron-SWIFT Training Documentation](https://swift.readthedocs.io/en/latest/Instruction/Megatron-SWIFT-Training.html). These topics will not be elaborated here."
msgstr "关于环境准备以及 HF 和 MCore 模型权重的转换，可以参考[Megatron-SWIFT训练文档](https://swift.readthedocs.io/zh-cn/latest/Instruction/Megatron-SWIFT%E8%AE%AD%E7%BB%83.html)。这里不展开介绍。"

#: ../../source/training/ms_swift.md:276 e4b6d48e1f5440ddbc5602e6860f7971
msgid "We will use Alibaba Cloud DLC to start the training The training environment consists of 2 machines with 8 * 80GiB A800 GPUs. For more information on multi-node startup methods, refer to [here](https://github.com/modelscope/ms-swift/tree/main/examples/train/multi-node)."
msgstr "我们将使用阿里云 DLC 启动训练。训练环境由2台配备8卡 80GiB A800 GPU 组成。关于多节点启动方法的更多信息，请参考[这里](https://github.com/modelscope/ms-swift/tree/main/examples/train/multi-node)。"

#: ../../source/training/ms_swift.md:316 62fd695e82d54817ae7e0a59ea0e0381
msgid "The custom dataset format is the same as `swift sft`, which can be found in the previous section. Simply specify `--dataset <dataset_path>`."
msgstr "自定义数据集格式与 `swift sft` 相同，详见之前章节。只需指定 `--dataset <dataset_path>` 即可。"

#: ../../source/training/ms_swift.md:318 bd84ae8eeaf248ffb43acb334e7626e7
msgid "The following is a comparison of training speed and GPU memory usage between `megatron sft` and `swift sft` for full-parameter fine-tuning of the Qwen3-30B-A3B model:"
msgstr "使用 `megatron sft` 和 `swift sft` 在对 Qwen3-30B-A3B 模型进行全参数微调的训练速度和 GPU 显存使用对比情况如下："

#: ../../source/training/ms_swift.md 6e220a7c28b14bcd85fd9af5804ab91e
msgid "Megatron-LM"
msgstr "Megatron-LM"

#: ../../source/training/ms_swift.md d5ab9738de6241f5837c0d94ef9108d4
msgid "DeepSpeed-ZeRO2"
msgstr "DeepSpeed-ZeRO2"

#: ../../source/training/ms_swift.md 301a5de6123c442b8ffa6711f4910363
msgid "DeepSpeed-ZeRO3"
msgstr "DeepSpeed-ZeRO3"

#: ../../source/training/ms_swift.md 35818d0633704fd3a70482e77a32f892
msgid "Training Speed"
msgstr "训练速度"

#: ../../source/training/ms_swift.md 6b8176dc1e724ccfbcea6ab0fec3f2d8
msgid "9.6s/it"
msgstr "9.6s/it"

#: ../../source/training/ms_swift.md c344266bde2c4703bad8f2cd5b19a2ef
msgid "-"
msgstr ""

#: ../../source/training/ms_swift.md 468b05aed5be4fcf9593ba2ad6545868
msgid "91.2s/it"
msgstr "91.2s/it"

#: ../../source/training/ms_swift.md ffcfa71deee14901a6e96f3424251197
msgid "GPU Memory Usage"
msgstr "显存使用"

#: ../../source/training/ms_swift.md 6c68f675c1c343debbebd40e725aa3af
msgid "16 * 60GiB"
msgstr "16 * 60GiB"

#: ../../source/training/ms_swift.md 76e6265fbb52487fa8b3a8e5dd04e9bd
msgid "OOM"
msgstr "OOM"

#: ../../source/training/ms_swift.md 676f4cc38dba4dd5b69e76186a6dc3a1
msgid "16 * 80GiB"
msgstr "16 * 80GiB"

#: ../../source/training/ms_swift.md:325 ebfe245e509c4d17aa0977330d1b7668
msgid "Conclusion"
msgstr "总结"

#: ../../source/training/ms_swift.md:327 0cd0194d11994c899616a43b9650c0b6
msgid "The above is the best practice for training Qwen3 series models using ms-swift. If you encounter any difficulties during use, please join the discussion in [this issue](https://github.com/modelscope/ms-swift/issues/4030)."
msgstr "以上为使用 ms-swift 训练 Qwen3 系列模型的最佳实践。如果在使用过程中遇到任何困难，请在[此 issue](https://github.com/modelscope/ms-swift/issues/4030)中参与讨论。"

